# for cuda api test(cudalaunchkernel cudamalloc cudafree cudamemcpy)

import torch
import os
import time
import gc
import traceback
import datetime
import numpy as np
import multiprocessing as mp
import sys
from torch.utils.data import DataLoader, TensorDataset

print(f"Python è¿›ç¨‹ PID: {os.getpid()}")
print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")
print(f"CUDA è®¾å¤‡æ•°é‡: {torch.cuda.device_count()}")
print(f"CUDA è®¾å¤‡åç§°: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A'}")

# æš‚åœï¼Œè®©æ‚¨æœ‰æ—¶é—´é™„åŠ è·Ÿè¸ªå™¨
print("ç­‰å¾… 5 ç§’ä»¥ä¾¿é™„åŠ è·Ÿè¸ªå™¨...")
time.sleep(5)

def print_memory_stats(prefix=""):
    """æ‰“å°å½“å‰GPUå†…å­˜ä½¿ç”¨æƒ…å†µ"""
    if torch.cuda.is_available():
        current_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f")
        allocated = torch.cuda.memory_allocated() / (1024 * 1024)
        reserved = torch.cuda.memory_reserved() / (1024 * 1024)
        print(f"[{current_time}] {prefix} GPUå†…å­˜ - å·²åˆ†é…: {allocated:.2f}MB, å·²ä¿ç•™: {reserved:.2f}MB")

def print_stack():
    """æ‰“å°å½“å‰è°ƒç”¨æ ˆï¼Œå¸¦æ—¶é—´æˆ³"""
    current_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f")
    stack = traceback.format_stack()[:-1]
    print(f"\n[{current_time}] å½“å‰ Python è°ƒç”¨æ ˆ:")
    for line in stack:
        print(f"  {line.strip()}")
    print("----------")

def force_cuda_allocation(size_mb, tag=""):
    """å¼ºåˆ¶åˆ†é…æŒ‡å®šå¤§å°çš„CUDAå†…å­˜"""
    print_stack()
    print_memory_stats(f"åˆ†é…å‰({tag})")
    tensor = torch.ones((size_mb * 256, 1024), device='cuda')  # çº¦1MB=1024*1024å­—èŠ‚
    print_memory_stats(f"åˆ†é…å({tag})")
    return tensor

def force_cuda_free(tensor, tag=""):
    """å¼ºåˆ¶é‡Šæ”¾CUDAå†…å­˜"""
    print_memory_stats(f"é‡Šæ”¾å‰({tag})")
    del tensor
    torch.cuda.empty_cache()  # å°è¯•é‡Šæ”¾æœªä½¿ç”¨çš„ç¼“å­˜
    print_memory_stats(f"é‡Šæ”¾å({tag})")
    return None

def create_model_with_buffers(complexity=1):
    """åˆ›å»ºåŒ…å«å¤šä¸ªç¼“å†²åŒºçš„æ¨¡å‹ï¼Œè§¦å‘å¤šæ¬¡å†…å­˜åˆ†é…"""
    class ComplexModel(torch.nn.Module):
        def __init__(self, complexity):
            super().__init__()
            self.complexity = complexity
            self.input_size = 32  # è¾“å…¥å›¾åƒå¤§å°
            
            # åˆ›å»ºå¤šä¸ªå±‚ï¼Œæ¯ä¸ªå±‚è§¦å‘å•ç‹¬çš„å†…å­˜åˆ†é…
            self.features = torch.nn.ModuleList()
            for i in range(complexity):
                # æ¯ä¸ªç‰¹å¾å—åŒ…å«å·ç§¯ã€æ‰¹å½’ä¸€åŒ–å’Œæ± åŒ–ï¼Œä¼šè§¦å‘å¤šæ¬¡å†…å­˜åˆ†é…
                self.features.append(torch.nn.Sequential(
                    torch.nn.Conv2d(3 if i == 0 else 16*2**min(i, 3), 16*2**min(i+1, 3), 3, padding=1),
                    torch.nn.BatchNorm2d(16*2**min(i+1, 3)),
                    torch.nn.ReLU(inplace=True),
                    torch.nn.MaxPool2d(2)
                ))
            
            # è®¡ç®—æœ€ç»ˆç‰¹å¾å›¾å¤§å°
            # æ¯ä¸ªæ± åŒ–å±‚å°†å¤§å°å‡åŠ
            final_size = self.input_size // (2 ** complexity)
            # æœ€å°ä¸º1x1ï¼Œé¿å…å‡ºç°å°äº1çš„æƒ…å†µ
            final_size = max(1, final_size)
            
            # è®¡ç®—å±•å¹³åçš„ç‰¹å¾ç»´åº¦
            final_channels = 16 * (2 ** min(complexity, 3))
            flattened_features = final_channels * final_size * final_size
            
            print(f"æ¨¡å‹ç‰¹å¾ç»´åº¦: {final_channels}x{final_size}x{final_size} = {flattened_features}")
            
            # æœ€åçš„åˆ†ç±»å±‚
            self.classifier = torch.nn.Sequential(
                torch.nn.Linear(flattened_features, 128),
                torch.nn.ReLU(inplace=True),
                torch.nn.Linear(128, 10)
            )
            
            # æ³¨å†Œç¼“å†²åŒºï¼Œè¿›ä¸€æ­¥å¢åŠ å†…å­˜åˆ†é…
            for i in range(complexity):
                size = 1000 * (i + 1)
                self.register_buffer(f'dummy_buffer_{i}', torch.randn(size, device='cuda'))
        
        def forward(self, x):
            # è°ƒè¯•è¾“å‡º
            if self.training:
                print(f"è¾“å…¥å½¢çŠ¶: {x.shape}")
                
            for i, feature in enumerate(self.features):
                x = feature(x)
                if self.training:
                    print(f"ç¬¬ {i+1} ç‰¹å¾å±‚åå½¢çŠ¶: {x.shape}")
            
            # å±•å¹³ç‰¹å¾å›¾
            x = x.view(x.size(0), -1)
            if self.training:
                print(f"å±•å¹³åå½¢çŠ¶: {x.shape}")
                print(f"åˆ†ç±»å™¨ç¬¬ä¸€å±‚æƒé‡å½¢çŠ¶: {self.classifier[0].weight.shape}")
            
            return self.classifier(x)
    
    print_memory_stats("æ¨¡å‹åˆ›å»ºå‰")
    model = ComplexModel(complexity).cuda()
    print_memory_stats("æ¨¡å‹åˆ›å»ºå")
    return model

def train_for_iterations(model, iterations=5, batch_size=32, input_size=(3, 32, 32)):
    """
    è¿è¡Œå¤šæ¬¡è®­ç»ƒè¿­ä»£ï¼Œæ¯æ¬¡è¿­ä»£è§¦å‘æ–°çš„å†…å­˜åˆ†é…å’Œé‡Šæ”¾
    ä¸»è¦æµ‹è¯•cudaMallocå’ŒcudaFreeçš„è°ƒç”¨
    """
    # åˆ›å»ºéšæœºæ•°æ®
    input_shape = (batch_size,) + input_size
    data = torch.randn(500, *input_size, device='cuda')
    labels = torch.randint(0, 10, (500,), device='cuda')
    dataset = TensorDataset(data, labels)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
    
    # è®¾ç½®ä¼˜åŒ–å™¨
    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)
    criterion = torch.nn.CrossEntropyLoss()
    
    # è®­ç»ƒå¾ªç¯
    for iteration in range(iterations):
        print(f"\n===== å¼€å§‹è¿­ä»£ {iteration+1}/{iterations} =====")
        total_loss = 0.0
        batch_count = 0
        
        # åœ¨æ¯ä¸ªè¿­ä»£å¼€å§‹æ—¶ï¼Œå¼ºåˆ¶åˆ†é…ä¸€äº›é¢å¤–å†…å­˜ï¼ˆæ¨¡æ‹Ÿç¼“å­˜ï¼‰
        cache_tensors = []
        if iteration % 2 == 0:  # å¶æ•°è¿­ä»£æ—¶åˆ†é…é¢å¤–å†…å­˜
            for i in range(2):
                cache_tensors.append(force_cuda_allocation(
                    20 + (iteration*5), f"è¿­ä»£{iteration+1}ä¸´æ—¶ç¼“å­˜{i+1}"))
        
        for inputs, targets in dataloader:
            # å¼ºåˆ¶æ‰§è¡Œåƒåœ¾å›æ”¶ï¼Œè§¦å‘å¯èƒ½çš„å†…å­˜é‡Šæ”¾
            gc.collect()
            
            try:
                # å‰å‘ä¼ æ’­
                print_memory_stats(f"è¿­ä»£{iteration+1}æ‰¹æ¬¡{batch_count+1}å‰å‘ä¼ æ’­å‰")
                outputs = model(inputs)
                loss = criterion(outputs, targets)
                print_memory_stats(f"è¿­ä»£{iteration+1}æ‰¹æ¬¡{batch_count+1}å‰å‘ä¼ æ’­å")
                
                # åå‘ä¼ æ’­å’Œä¼˜åŒ–
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                
                total_loss += loss.item()
            except Exception as e:
                print(f"è®­ç»ƒä¸­å‘ç”Ÿé”™è¯¯: {e}")
                traceback.print_exc()
                # ç»§ç»­ä¸‹ä¸€ä¸ªæ‰¹æ¬¡
            
            batch_count += 1
            if batch_count >= 3:  # æ¯ä¸ªè¿­ä»£ä»…å¤„ç†3ä¸ªæ‰¹æ¬¡
                break
        
        # æ‰‹åŠ¨é‡Šæ”¾ä¸€äº›ç¼“å­˜å†…å­˜
        if len(cache_tensors) > 0:
            print("\n>> é‡Šæ”¾ä¸´æ—¶ç¼“å­˜...")
            for i, tensor in enumerate(cache_tensors):
                force_cuda_free(tensor, f"è¿­ä»£{iteration+1}ä¸´æ—¶ç¼“å­˜{i+1}é‡Šæ”¾")
            cache_tensors = []
        
        # æ¯éš”ä¸€å®šè¿­ä»£ï¼Œé‡å»ºæŸäº›æ¨¡å‹ç»„ä»¶ä»¥è§¦å‘æ›´å¤šçš„å†…å­˜æ“ä½œ
        if iteration % 2 == 1:  # å¥‡æ•°è¿­ä»£æ—¶é‡å»ºéƒ¨åˆ†æ¨¡å‹
            print("\n>> é‡å»ºæ¨¡å‹ç»„ä»¶...")
            # å¤‡ä»½æ—§å‚æ•°
            print_memory_stats("é‡å»ºæ¨¡å‹å‰")
            
            try:
                # ä¿å­˜ç¬¬ä¸€å±‚çš„è¾“å…¥ç‰¹å¾å¤§å°
                in_features = model.classifier[0].in_features
                
                # æ›¿æ¢åˆ†ç±»å™¨ï¼Œè§¦å‘æ–°å†…å­˜åˆ†é…å’Œæ—§å†…å­˜é‡Šæ”¾
                old_classifier = model.classifier
                model.classifier = torch.nn.Sequential(
                    torch.nn.Linear(in_features, 128 + (iteration * 10) % 64),
                    torch.nn.ReLU(inplace=True),
                    torch.nn.Linear(128 + (iteration * 10) % 64, 10)
                ).cuda()
                
                # å¼ºåˆ¶é‡Šæ”¾æ—§åˆ†ç±»å™¨
                del old_classifier
                torch.cuda.empty_cache()
            except Exception as e:
                print(f"é‡å»ºæ¨¡å‹æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                
            print_memory_stats("é‡å»ºæ¨¡å‹å")
        
        if batch_count > 0:
            print(f"è¿­ä»£ {iteration+1} å¹³å‡æŸå¤±: {total_loss/batch_count:.4f}")
        
        # å‘¨æœŸæ€§åœ°å°è¯•æ¸…ç©ºç¼“å­˜å’Œæ”¶é›†åƒåœ¾
        if iteration % 2 == 0:
            print("\n>> å¼ºåˆ¶æ¸…ç†å†…å­˜...")
            print_memory_stats("æ¸…ç†å‰")
            gc.collect()
            torch.cuda.empty_cache()
            print_memory_stats("æ¸…ç†å")
    
    return model


def test_large_model_transfers(iterations=10, model_complexity=50):
    """
    æµ‹è¯•å°†å¤§å‹ç¥ç»ç½‘ç»œæ¨¡å‹åœ¨GPUå’ŒCPUä¹‹é—´åå¤ä¼ è¾“ï¼Œ
    å¹¶ç¡®ä¿æ¯æ¬¡è¿­ä»£éƒ½æ¸…ç©ºç¼“å­˜
    æµ‹è¯•cudaMemcpyçš„è°ƒç”¨
    """
    print("\n===== å¼€å§‹å¤§å‹æ¨¡å‹ GPU-CPU ä¼ è¾“æµ‹è¯• =====")
    print(f"å½“å‰è¿›ç¨‹ PID: {os.getpid()}")
    
    print_memory_stats("å¤§å‹æ¨¡å‹åˆ›å»ºå‰")
    # åˆ›å»ºä¸€ä¸ªæ›´å¤æ‚çš„å¤§å‹æ¨¡å‹
    model = create_model_with_buffers(complexity=model_complexity)
    print(f"åˆ›å»ºäº†å¤æ‚åº¦ä¸º {model_complexity} çš„å¤§å‹æ¨¡å‹")
    print_memory_stats("å¤§å‹æ¨¡å‹åˆ›å»ºå")
    
    # æ·»åŠ æ›´å¤šå‚æ•°ï¼Œå¢åŠ æ¨¡å‹å¤§å°
    # æ·»åŠ å¤§é‡çš„é¢å¤–ç¼“å†²åŒºï¼Œå¢åŠ å†…å­˜ä½¿ç”¨é‡
    for i in range(10):
        buffer_size = 500000 * (i + 1)  # çº¦2MBæ¯ä¸ªç¼“å†²åŒº
        model.register_buffer(f'extra_large_buffer_{i}', torch.randn(buffer_size, device='cuda'))
        print(f"æ·»åŠ äº†é¢å¤–ç¼“å†²åŒº {i+1}ï¼Œå¤§å°: {buffer_size * 4 / (1024*1024):.2f}MB")
    
    print_memory_stats("æ·»åŠ é¢å¤–ç¼“å†²åŒºå")
    
    # è®°å½•æ¨¡å‹å¤§å°
    param_size = 0
    buffer_size = 0
    
    # è®¡ç®—å‚æ•°å¤§å°
    for param in model.parameters():
        param_size += param.nelement() * param.element_size()
    
    # è®¡ç®—ç¼“å†²åŒºå¤§å°
    for buffer in model.buffers():
        buffer_size += buffer.nelement() * buffer.element_size()
    
    total_size = param_size + buffer_size
    print(f"æ¨¡å‹æ€»å¤§å°: {total_size / (1024*1024):.2f}MB")
    print(f"  - å‚æ•°å¤§å°: {param_size / (1024*1024):.2f}MB")
    print(f"  - ç¼“å†²åŒºå¤§å°: {buffer_size / (1024*1024):.2f}MB")
    
    # æ‰§è¡Œå¤šæ¬¡ä¼ è¾“
    for i in range(iterations):
        print(f"\n----- å¤§å‹æ¨¡å‹ä¼ è¾“è¿­ä»£ {i+1}/{iterations} -----")
        
        # åœ¨æ¯æ¬¡è¿­ä»£å¼€å§‹å‰æ¸…ç©ºç¼“å­˜
        gc.collect()
        torch.cuda.empty_cache()
        print_memory_stats("è¿­ä»£å¼€å§‹å‰ç¼“å­˜æ¸…ç†å")
        
        # GPU -> CPU ä¼ è¾“
        print("\n>> å¤§å‹æ¨¡å‹ GPUåˆ°CPUä¼ è¾“æµ‹è¯•")
        print_memory_stats("GPU->CPU ä¼ è¾“å‰")
        print_stack()
        start_time = time.time()
        cpu_model = model.cpu()
        end_time = time.time()
        transfer_time = end_time - start_time
        print(f"GPU->CPU ä¼ è¾“å®Œæˆ: {transfer_time:.4f} ç§’")
        transfer_speed = total_size / transfer_time / (1024*1024)
        print(f"ä¼ è¾“é€Ÿåº¦: {transfer_speed:.2f} MB/s")
        device = next(cpu_model.parameters()).device
        print(f"æ¨¡å‹å½“å‰ä½ç½®: {device}")
        print_memory_stats("GPU->CPU ä¼ è¾“å")
        
        # æ¸…ç©ºGPUç¼“å­˜
        gc.collect()
        torch.cuda.empty_cache()
        print_memory_stats("GPU->CPU ä¼ è¾“åç¼“å­˜æ¸…ç†")
        
        # ç¨å¾®ä¿®æ”¹ä¸€ä¸‹CPUä¸Šçš„æ¨¡å‹æ•°æ®
        for name, param in cpu_model.named_parameters():
            if 'weight' in name and i % 2 == 0:
                with torch.no_grad():
                    noise = torch.randn_like(param.data) * 0.01
                    param.data = param.data + noise
        
        # CPU -> GPU ä¼ è¾“
        print("\n>> å¤§å‹æ¨¡å‹ CPUåˆ°GPUä¼ è¾“æµ‹è¯•")
        print_memory_stats("CPU->GPU ä¼ è¾“å‰")
        print_stack()
        start_time = time.time()
        gpu_model = cpu_model.cuda()
        torch.cuda.synchronize()  # ç¡®ä¿ä¼ è¾“å®Œæˆ
        end_time = time.time()
        transfer_time = end_time - start_time
        print(f"CPU->GPU ä¼ è¾“å®Œæˆ: {transfer_time:.4f} ç§’")
        transfer_speed = total_size / transfer_time / (1024*1024)
        print(f"ä¼ è¾“é€Ÿåº¦: {transfer_speed:.2f} MB/s")
        device = next(gpu_model.parameters()).device
        print(f"æ¨¡å‹å½“å‰ä½ç½®: {device}")
        print_memory_stats("CPU->GPU ä¼ è¾“å")
        
        # ç¡®ä¿æ¨¡å‹å¼•ç”¨æ­£ç¡®
        model = gpu_model
        
        # æ›´æ–°æ¨¡å‹çš„ä¸€äº›å‚æ•°ä»¥é¿å…ä¼˜åŒ–
        if i % 2 == 0:
            # æ›´æ–°éšæœºæƒé‡ä»¥ç¡®ä¿ä¼ è¾“ä¸è¢«ä¼˜åŒ–æ‰
            for name, param in model.named_parameters():
                if 'weight' in name:
                    param.data = param.data + torch.randn_like(param.data) * 0.01
        
        # æ¸…ç©ºCPUä¸Šæ¨¡å‹çš„å¼•ç”¨å’Œå…¶ä»–ä¸´æ—¶å˜é‡
        del cpu_model
        gc.collect()
        
        # æ¯éš”å‡ æ¬¡è¿­ä»£æ‰§è¡Œä¸€æ¬¡æ¨ç†ï¼Œç¡®ä¿æ¨¡å‹åŠŸèƒ½æ­£å¸¸
        if i % 2 == 0:
            try:
                print("\n>> æ‰§è¡Œå¤§å‹æ¨¡å‹æµ‹è¯•æ¨ç†")
                dummy_input = torch.randn(2, 3, 32, 32, device='cuda')
                with torch.no_grad():
                    output = model(dummy_input)
                print(f"æ¨ç†è¾“å‡ºå½¢çŠ¶: {output.shape}")
                # æ¸…ç†æ¨ç†åçš„ç¼“å­˜
                del dummy_input, output
                gc.collect()
                torch.cuda.empty_cache()
            except Exception as e:
                print(f"æ¨ç†å¤±è´¥: {e}")
                traceback.print_exc()
        
        # æ¯æ¬¡è¿­ä»£ç»“æŸæ—¶æ¸…ç©ºç¼“å­˜
        gc.collect()
        torch.cuda.empty_cache()
        print_memory_stats("è¿­ä»£ç»“æŸåç¼“å­˜æ¸…ç†")
        
        # åœ¨å¤šæ¬¡è¿­ä»£ä¹‹é—´æ·»åŠ çŸ­æš‚å»¶è¿Ÿ
        print("ç­‰å¾… 1 ç§’...")
        time.sleep(1)  # 1ç§’å»¶è¿Ÿï¼Œä¾¿äºè§‚å¯Ÿ
    
    print("\n===== å¤§å‹æ¨¡å‹ä¼ è¾“æµ‹è¯•å®Œæˆ =====")
    print_memory_stats("æœ€ç»ˆçŠ¶æ€")
    
    # æ‰‹åŠ¨æ¸…ç†æ¨¡å‹å’Œå…¶ä»–èµ„æº
    print("æ¸…ç†æ‰€æœ‰èµ„æº...")
    del model, gpu_model
    gc.collect()
    torch.cuda.empty_cache()
    print_memory_stats("æ¸…ç†å")
    
    return True

def test_custom_cuda_operations(size_mb=50):
    """
    æµ‹è¯•è‡ªå®šä¹‰ CUDA æ“ä½œï¼Œè§¦å‘æ›´å¤š cudaMemcpy è°ƒç”¨
    """
    print("\n===== å¼€å§‹è‡ªå®šä¹‰ CUDA æ“ä½œæµ‹è¯• =====")
    print_memory_stats("æµ‹è¯•å¼€å§‹")
    
    # åˆ›å»ºç”¨äºæ“ä½œçš„å¼ é‡
    a = torch.rand((size_mb * 64, 1024), device='cuda')
    b = torch.rand((size_mb * 64, 1024), device='cuda')
    
    # æ‰§è¡Œå¤šä¸ª CUDA æ“ä½œï¼Œè¿™äº›ä¼šåˆ›å»ºæ–°çš„ä¸´æ—¶å¼ é‡å¹¶è§¦å‘ cudaMemcpy
    print("\n>> æ‰§è¡Œ CUDA å¼ é‡æ“ä½œ")
    start_time = time.time()
    
    # 1. é€å…ƒç´ æ“ä½œ
    c = a * b
    
    # 2. çŸ©é˜µä¹˜æ³•ï¼ˆä¼šè§¦å‘å¤§é‡ CUDA æ ¸å¿ƒè¿ç®—å’Œå†…å­˜æ“ä½œï¼‰
    try:
        a_2d = a[:1024, :1024]
        b_2d = b[:1024, :1024]
        d = torch.matmul(a_2d, b_2d)
    except Exception as e:
        print(f"çŸ©é˜µä¹˜æ³•å¤±è´¥: {e}")
        d = a[:100, :100] @ b[:100, :100]
    
    # 3. æ“ä½œä¸åŒè®¾å¤‡ä¸Šçš„æ•°æ®
    cpu_tensor = torch.rand((1000, 1000))
    e = c[:100, :100] + cpu_tensor[:100, :100].cuda()
    
    # 4. å¤šæ¬¡åœ¨ CPU å’Œ GPU ä¹‹é—´å¤åˆ¶ç›¸åŒæ•°æ®
    for i in range(5):
        temp = d.cpu()
        d_copy = temp.cuda()
    
    # 5. ä½¿ç”¨ torch.to() åœ¨è®¾å¤‡ä¹‹é—´ä¼ è¾“
    f = e.to('cpu').to('cuda')
    
    end_time = time.time()
    print(f"CUDA æ“ä½œå®Œæˆ: {end_time - start_time:.4f} ç§’")
    print_memory_stats("CUDA æ“ä½œå")
    
    # æ¸…ç†
    del a, b, c, d, e, f, cpu_tensor
    torch.cuda.empty_cache()
    print_memory_stats("å†…å­˜æ¸…ç†å")

def run_inference_tests(model, count=3):
    """è¿è¡Œå‡ æ¬¡æ¨ç†ï¼Œè§¦å‘æ›´å¤šå†…å­˜æ“ä½œ"""
    print("\n===== å¼€å§‹æ¨ç†æµ‹è¯• =====")
    
    for i in range(count):
        try:
            # åˆ›å»ºä¸åŒå¤§å°çš„è¾“å…¥ï¼Œè§¦å‘ä¸åŒå¤§å°çš„å†…å­˜åˆ†é…
            size = 32 * (i + 1)
            batch_size = 4 * (i + 1)
            
            print(f"\n>> æ¨ç†æµ‹è¯• {i+1}: å¤§å°={size}, æ‰¹æ¬¡å¤§å°={batch_size}")
            input_tensor = torch.randn(batch_size, 3, size, size, device='cuda')
            
            print_memory_stats("æ¨ç†å‰")
            # æ‰§è¡Œæ¨ç†
            with torch.no_grad():
                try:
                    # ç¦ç”¨è®­ç»ƒæ¨¡å¼ä»¥é¿å…è°ƒè¯•è¾“å‡º
                    model.train(False)
                    output = model(input_tensor)
                    print(f"æ¨ç†è¾“å‡ºå½¢çŠ¶: {output.shape}")
                except Exception as e:
                    print(f"æ¨ç†å¤±è´¥: {e}")
                finally:
                    # æ¢å¤è®­ç»ƒæ¨¡å¼
                    model.train(True)
            print_memory_stats("æ¨ç†å")
        except Exception as e:
            print(f"æ¨ç†æµ‹è¯• {i+1} å¤±è´¥: {e}")
        finally:
            # æ‰‹åŠ¨é‡Šæ”¾è¾“å…¥å¼ é‡
            try:
                del input_tensor
                torch.cuda.empty_cache()
            except:
                pass
            
def test_explicit_cuda_api_calls():
    """
    ä½¿ç”¨ ctypes ç›´æ¥è°ƒç”¨ CUDA Runtime API
    ä¸»è¦æµ‹è¯•cuda APIçš„ç›´æ¥è°ƒç”¨
    """
    import ctypes
    from ctypes import c_void_p, c_size_t, c_int, byref, CDLL
    
    print("\n===== å¼€å§‹æ˜¾å¼ CUDA API è°ƒç”¨æµ‹è¯• =====")
    
    # åŠ è½½ CUDA Runtime åº“
    try:
        cuda = CDLL('libcudart.so')
        print("æˆåŠŸåŠ è½½ CUDA Runtime åº“")
    except Exception as e:
        print(f"æ— æ³•åŠ è½½ CUDA Runtime åº“: {e}")
        return
    
    # å®šä¹‰ä¸€äº›å¸¸é‡
    cudaSuccess = 0
    cudaMemcpyHostToDevice = 1
    cudaMemcpyDeviceToHost = 2
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    size = 10 * 1024 * 1024  # 10MB
    h_data = (ctypes.c_float * (size // 4))()
    for i in range(len(h_data)):
        h_data[i] = 1.0
    
    print(f"å·²åˆ›å»ºä¸»æœºå†…å­˜æ•°æ®ï¼Œå¤§å°: {size / (1024*1024):.2f} MB")
    
    # åˆ†é…è®¾å¤‡å†…å­˜ - cudaMalloc
    d_data = c_void_p()
    print("\n>> è°ƒç”¨ cudaMalloc API")
    print_stack()
    ret = cuda.cudaMalloc(byref(d_data), size)
    if ret != cudaSuccess:
        print(f"cudaMalloc å¤±è´¥ï¼Œé”™è¯¯ç : {ret}")
        return
    print(f"cudaMalloc æˆåŠŸï¼Œåˆ†é…äº† {size / (1024*1024):.2f} MB")
    print_memory_stats("cudaMalloc å")
    
    # ä»ä¸»æœºå¤åˆ¶åˆ°è®¾å¤‡ - cudaMemcpy (H2D)
    print("\n>> è°ƒç”¨ cudaMemcpy API (H2D)")
    print_stack()
    start_time = time.time()
    ret = cuda.cudaMemcpy(d_data, ctypes.cast(h_data, c_void_p), size, cudaMemcpyHostToDevice)
    if ret != cudaSuccess:
        print(f"cudaMemcpy H2D å¤±è´¥ï¼Œé”™è¯¯ç : {ret}")
        cuda.cudaFree(d_data)
        return
    end_time = time.time()
    print(f"cudaMemcpy H2D æˆåŠŸ: {end_time - start_time:.4f} ç§’")
    print_memory_stats("cudaMemcpy H2D å")
    
    # ä»è®¾å¤‡å¤åˆ¶åˆ°ä¸»æœº - cudaMemcpy (D2H)
    h_result = (ctypes.c_float * (size // 4))()
    print("\n>> è°ƒç”¨ cudaMemcpy API (D2H)")
    print_stack()
    start_time = time.time()
    ret = cuda.cudaMemcpy(ctypes.cast(h_result, c_void_p), d_data, size, cudaMemcpyDeviceToHost)
    if ret != cudaSuccess:
        print(f"cudaMemcpy D2H å¤±è´¥ï¼Œé”™è¯¯ç : {ret}")
        cuda.cudaFree(d_data)
        return
    end_time = time.time()
    print(f"cudaMemcpy D2H æˆåŠŸ: {end_time - start_time:.4f} ç§’")
    print_memory_stats("cudaMemcpy D2H å")
    
    # éªŒè¯æ•°æ®
    valid = True
    for i in range(min(10, len(h_result))):
        if h_result[i] != 1.0:
            valid = False
            print(f"æ•°æ®éªŒè¯å¤±è´¥: h_result[{i}] = {h_result[i]}")
            break
    if valid:
        print("æ•°æ®éªŒè¯æˆåŠŸ")
    
    # åˆ†é…ç¬¬äºŒå—è®¾å¤‡å†…å­˜ç”¨äºè®¾å¤‡é—´å¤åˆ¶
    d_data2 = c_void_p()
    print("\n>> è°ƒç”¨ç¬¬äºŒæ¬¡ cudaMalloc API")
    ret = cuda.cudaMalloc(byref(d_data2), size)
    if ret == cudaSuccess:
        # è®¾å¤‡åˆ°è®¾å¤‡å¤åˆ¶ - cudaMemcpy (D2D)
        print("\n>> è°ƒç”¨ cudaMemcpy API (D2D)")
        start_time = time.time()
        ret = cuda.cudaMemcpy(d_data2, d_data, size, 3)  # 3 = cudaMemcpyDeviceToDevice
        end_time = time.time()
        if ret == cudaSuccess:
            print(f"cudaMemcpy D2D æˆåŠŸ: {end_time - start_time:.4f} ç§’")
        else:
            print(f"cudaMemcpy D2D å¤±è´¥ï¼Œé”™è¯¯ç : {ret}")
        
        # é‡Šæ”¾ç¬¬äºŒå—å†…å­˜
        print("\n>> è°ƒç”¨ç¬¬äºŒæ¬¡ cudaFree API")
        cuda.cudaFree(d_data2)
    
    # é‡Šæ”¾è®¾å¤‡å†…å­˜ - cudaFree
    print("\n>> è°ƒç”¨ cudaFree API")
    print_stack()
    ret = cuda.cudaFree(d_data)
    if ret != cudaSuccess:
        print(f"cudaFree å¤±è´¥ï¼Œé”™è¯¯ç : {ret}")
    else:
        print("cudaFree æˆåŠŸ")
    print_memory_stats("cudaFree å")
    
    print("\n===== æ˜¾å¼ CUDA API è°ƒç”¨æµ‹è¯•å®Œæˆ =====")

def worker_process(worker_id, size_mb=100, iterations=10, delay=1.0):
    """å·¥ä½œè¿›ç¨‹å‡½æ•°ï¼Œæ‰§è¡Œ CUDA æ“ä½œ"""
    print(f"å·¥ä½œè¿›ç¨‹ {worker_id} å¯åŠ¨ (PID: {os.getpid()})")
    print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")
    
    try:
        # ç­‰å¾…ä¸€æ®µæ—¶é—´ä»¥ä¾¿äºé™„åŠ åˆ†æå·¥å…·
        print(f"å·¥ä½œè¿›ç¨‹ {worker_id} ç­‰å¾… {delay} ç§’...")
        time.sleep(delay)
        
        tensors = []
        
        # åˆ†é…å†…å­˜
        print(f"å·¥ä½œè¿›ç¨‹ {worker_id} å¼€å§‹åˆ†é…å†…å­˜...")
        for i in range(iterations):
            print(f"å·¥ä½œè¿›ç¨‹ {worker_id} è¿­ä»£ {i+1}/{iterations}")
            print_memory_stats(f"å·¥ä½œè¿›ç¨‹ {worker_id} åˆ†é…å‰")
            
            # åˆ†é… GPU å†…å­˜å¹¶æ‰§è¡Œä¸€äº›æ“ä½œ
            tensor = torch.ones((size_mb * 256, 1024), device='cuda')
            tensors.append(tensor)
            
            # æ‰§è¡Œä¸€äº› CUDA æ“ä½œ
            result = tensor * 2.0
            tensor.copy_(result)
            
            print_memory_stats(f"å·¥ä½œè¿›ç¨‹ {worker_id} åˆ†é…å")
            
            # å®šæœŸæ‰§è¡Œå†…å­˜å¤åˆ¶æ“ä½œ
            if i % 2 == 0:
                print(f"å·¥ä½œè¿›ç¨‹ {worker_id} æ‰§è¡Œ CPU<->GPU å†…å­˜å¤åˆ¶")
                cpu_tensor = tensor.cpu()
                new_gpu_tensor = cpu_tensor.cuda()
                tensors.append(new_gpu_tensor)
            
            # æ ¹æ®è®¾ç½®çš„å»¶è¿Ÿæš‚åœ
            time.sleep(delay)
        
        # é‡Šæ”¾ä¸€éƒ¨åˆ†å†…å­˜
        num_to_free = len(tensors) // 2
        print(f"å·¥ä½œè¿›ç¨‹ {worker_id} é‡Šæ”¾ {num_to_free} ä¸ªå¼ é‡...")
        for i in range(num_to_free):
            del tensors[0]
            torch.cuda.empty_cache()
        
        # ç®€å•çš„çŸ©é˜µè¿ç®—æµ‹è¯•
        print(f"å·¥ä½œè¿›ç¨‹ {worker_id} æ‰§è¡ŒçŸ©é˜µè¿ç®—...")
        matrix_size = 1000
        a = torch.randn((matrix_size, matrix_size), device='cuda')
        b = torch.randn((matrix_size, matrix_size), device='cuda')
        c = torch.matmul(a, b)
        print(f"çŸ©é˜µä¹˜æ³•ç»“æœå½¢çŠ¶: {c.shape}")
        
        # é‡Šæ”¾æ‰€æœ‰å†…å­˜
        print(f"å·¥ä½œè¿›ç¨‹ {worker_id} é‡Šæ”¾æ‰€æœ‰å†…å­˜...")
        del tensors, a, b, c
        torch.cuda.empty_cache()
        print_memory_stats(f"å·¥ä½œè¿›ç¨‹ {worker_id} ç»“æŸ")
        
    except Exception as e:
        print(f"å·¥ä½œè¿›ç¨‹ {worker_id} å‘ç”Ÿé”™è¯¯: {str(e)}")
        
    finally:
        print(f"å·¥ä½œè¿›ç¨‹ {worker_id} ç»“æŸè¿è¡Œ")
        # æ˜¾å¼é€€å‡ºï¼Œç¡®ä¿è¿›ç¨‹ç»ˆæ­¢
        sys.exit(0)

def run_multiprocess_test(num_processes=3, size_mb=100, iterations=10, delay=1.0):
    """
    å¯åŠ¨å¤šä¸ªå·¥ä½œè¿›ç¨‹
    æµ‹è¯•å¤šè¿›ç¨‹ä¸‹çš„ CUDA æ“ä½œ
    """
    print(f"ä¸»è¿›ç¨‹ PID: {os.getpid()}")
    print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")
    print(f"CUDA è®¾å¤‡æ•°é‡: {torch.cuda.device_count()}")
    print(f"CUDA è®¾å¤‡åç§°: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A'}")
    
    print(f"å¯åŠ¨ {num_processes} ä¸ªå·¥ä½œè¿›ç¨‹...")
    
    # åˆ›å»ºå¹¶å¯åŠ¨å·¥ä½œè¿›ç¨‹
    processes = []
    for i in range(num_processes):
        # æ¯ä¸ªè¿›ç¨‹çš„å†…å­˜å¤§å°å’Œè¿­ä»£æ¬¡æ•°ç•¥æœ‰ä¸åŒï¼Œä½¿æµ‹è¯•æ›´å¤šæ ·åŒ–
        p_size = size_mb + (i * 10)
        p_iterations = iterations + (i % 3)
        # å»¶è¿Ÿå¯åŠ¨ï¼Œä»¥ä¾¿äºå·¥å…·è¿æ¥
        p_delay = delay + (i * 0.5)
        
        p = mp.Process(
            target=worker_process, 
            args=(i+1, p_size, p_iterations, p_delay)
        )
        processes.append(p)
        p.start()
        print(f"å·²å¯åŠ¨å·¥ä½œè¿›ç¨‹ {i+1}, PID: {p.pid}")
        
        # ä¸»è¿›ç¨‹ç¨ä½œç­‰å¾…ï¼Œé¿å…æ‰€æœ‰è¿›ç¨‹åŒæ—¶å¯åŠ¨
        time.sleep(1.0)
    
    # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
    print("ç­‰å¾…æ‰€æœ‰å·¥ä½œè¿›ç¨‹å®Œæˆ...")
    for i, p in enumerate(processes):
        p.join()
        print(f"å·¥ä½œè¿›ç¨‹ {i+1} å·²ç»“æŸ")
    
    print("æ‰€æœ‰å·¥ä½œè¿›ç¨‹å·²å®Œæˆ")


def test_error_cuda_operations():
    """
    æµ‹è¯• CUDA æ“ä½œä¸­çš„é”™è¯¯å¤„ç†
    ä¸ºäº†è§¦å‘cudaMallocæ—¶çš„é”™è¯¯ï¼Œå°è¯•åˆ†é…ä¸€ä¸ªè¿‡å¤§çš„å†…å­˜å—
    """
    print("\n===== æµ‹è¯• CUDA æ“ä½œä¸­çš„é”™è¯¯å¤„ç† =====")
    print_memory_stats("æµ‹è¯• CUDA æ“ä½œä¸­çš„é”™è¯¯å¤„ç†å‰")
    try:
        # å°è¯•åˆ†é…ä¸€ä¸ªè¿‡å¤§çš„å†…å­˜å—
        time.sleep(2)
        d_data = torch.empty(1000000000000, device='cuda')
        time.sleep(2)  # ç¡®ä¿åˆ†é…å®Œæˆ
    except RuntimeError as e:
        print(f"æ•è·åˆ° RuntimeError: {str(e)}")
    finally:
        print_memory_stats("æµ‹è¯• CUDA æ“ä½œä¸­çš„é”™è¯¯å¤„ç†å")
        
        
def test_memory_leak_and_oom(duration_minutes=5, oom_interval_sec=30):
    """
    æŒç»­åˆ†é…å†…å­˜è€Œä¸é‡Šæ”¾ï¼Œæ¨¡æ‹Ÿå†…å­˜æ³„æ¼ï¼Œå¹¶å®šæœŸè§¦å‘OOMé”™è¯¯
    
    Args:
        duration_minutes: æµ‹è¯•æŒç»­æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰
        oom_interval_sec: è§¦å‘OOMæµ‹è¯•çš„é—´éš”ï¼ˆç§’ï¼‰
    """
    print(f"\n===== å¼€å§‹å†…å­˜æ³„æ¼å’ŒOOMæµ‹è¯• =====")
    print(f"æµ‹è¯•æŒç»­æ—¶é—´: {duration_minutes} åˆ†é’Ÿ")
    print(f"OOMæµ‹è¯•é—´éš”: {oom_interval_sec} ç§’")
    print(f"å½“å‰è¿›ç¨‹ PID: {os.getpid()}")
    
    # å­˜å‚¨åˆ†é…çš„å¼ é‡ï¼Œæ¨¡æ‹Ÿå†…å­˜æ³„æ¼
    leaked_tensors = []
    allocation_counter = 0
    start_time = time.time()
    last_oom_time = start_time
    
    # è·å–GPUæ€»å†…å­˜ä¿¡æ¯
    if torch.cuda.is_available():
        gpu_properties = torch.cuda.get_device_properties(0)
        total_memory = gpu_properties.total_memory
        print(f"GPUæ€»å†…å­˜: {total_memory / (1024**3):.2f} GB")
    else:
        print("CUDAä¸å¯ç”¨ï¼Œé€€å‡ºæµ‹è¯•")
        return
    
    print_memory_stats("æµ‹è¯•å¼€å§‹å‰")
    
    try:
        while True:
            current_time = time.time()
            elapsed_time = current_time - start_time
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æµ‹è¯•æ—¶é—´é™åˆ¶
            if elapsed_time > duration_minutes * 60:
                print(f"\næµ‹è¯•æ—¶é—´å·²è¾¾åˆ° {duration_minutes} åˆ†é’Ÿï¼Œç»“æŸæµ‹è¯•")
                break
            
            allocation_counter += 1
            
            # åŠ¨æ€å†³å®šåˆ†é…ç­–ç•¥
            if allocation_counter % 10 == 0:
                # æ¯10æ¬¡åˆ†é…ä¸€ä¸ªå¤§å†…å­˜å— (50-200MB)
                size_mb = np.random.randint(50, 201)
                block_type = "å¤§å†…å­˜å—"
                print(f"\n[{allocation_counter:04d}] åˆ†é…{block_type}: {size_mb}MB")
                
                try:
                    print_stack()
                    print_memory_stats(f"åˆ†é…{block_type}å‰")
                    tensor = torch.ones((size_mb * 256, 1024), device='cuda', dtype=torch.float32)
                    leaked_tensors.append(tensor)
                    print_memory_stats(f"åˆ†é…{block_type}å")
                    print(f"âœ“ æˆåŠŸåˆ†é…{block_type} {size_mb}MBï¼Œç´¯è®¡æ³„æ¼å¼ é‡: {len(leaked_tensors)}")
                    
                except RuntimeError as e:
                    print(f"âœ— åˆ†é…{block_type}å¤±è´¥: {str(e)}")
                    if "out of memory" in str(e).lower():
                        print("æ£€æµ‹åˆ°æ˜¾å­˜ä¸è¶³é”™è¯¯")
                    
            elif allocation_counter % 3 == 0:
                # æ¯3æ¬¡åˆ†é…ä¸€ä¸ªä¸­ç­‰å†…å­˜å— (10-30MB)
                size_mb = np.random.randint(10, 31)
                block_type = "ä¸­ç­‰å†…å­˜å—"
                print(f"\n[{allocation_counter:04d}] åˆ†é…{block_type}: {size_mb}MB")
                
                try:
                    print_memory_stats(f"åˆ†é…{block_type}å‰")
                    tensor = torch.randn((size_mb * 256, 1024), device='cuda', dtype=torch.float32)
                    leaked_tensors.append(tensor)
                    print_memory_stats(f"åˆ†é…{block_type}å")
                    print(f"âœ“ æˆåŠŸåˆ†é…{block_type} {size_mb}MBï¼Œç´¯è®¡æ³„æ¼å¼ é‡: {len(leaked_tensors)}")
                    
                except RuntimeError as e:
                    print(f"âœ— åˆ†é…{block_type}å¤±è´¥: {str(e)}")
                    if "out of memory" in str(e).lower():
                        print("æ£€æµ‹åˆ°æ˜¾å­˜ä¸è¶³é”™è¯¯")
                        
            else:
                # å¤§éƒ¨åˆ†æ—¶é—´åˆ†é…å°å†…å­˜ç¢ç‰‡ (1-5MB)
                size_mb = np.random.randint(1, 6)
                block_type = "å°å†…å­˜ç¢ç‰‡"
                print(f"[{allocation_counter:04d}] åˆ†é…{block_type}: {size_mb}MB", end="")
                
                try:
                    tensor = torch.zeros((size_mb * 256, 1024), device='cuda', dtype=torch.float32)
                    leaked_tensors.append(tensor)
                    print(f" âœ“ æˆåŠŸï¼Œç´¯è®¡: {len(leaked_tensors)}")
                    
                    # æ¯50ä¸ªå°ç¢ç‰‡æ‰“å°ä¸€æ¬¡å†…å­˜çŠ¶æ€
                    if allocation_counter % 50 == 0:
                        print_memory_stats(f"å°ç¢ç‰‡åˆ†é…ç¬¬{allocation_counter}æ¬¡å")
                        
                except RuntimeError as e:
                    print(f" âœ— å¤±è´¥: {str(e)}")
                    if "out of memory" in str(e).lower():
                        print("æ£€æµ‹åˆ°æ˜¾å­˜ä¸è¶³é”™è¯¯")
            
            # å®šæœŸå°è¯•åˆ†é…è¶…å¤§å†…å­˜å¯¼è‡´OOM
            if current_time - last_oom_time >= oom_interval_sec:
                print(f"\n{'='*60}")
                print(f"[OOMæµ‹è¯•] ç¬¬ {int((current_time - start_time) // oom_interval_sec) + 1} æ¬¡OOMæµ‹è¯•")
                print(f"{'='*60}")
                
                try:
                    # è·å–å½“å‰å¯ç”¨å†…å­˜
                    current_allocated = torch.cuda.memory_allocated()
                    current_reserved = torch.cuda.memory_reserved()
                    free_memory = total_memory - current_reserved
                    
                    print(f"å½“å‰å·²åˆ†é…: {current_allocated / (1024**3):.2f} GB")
                    print(f"å½“å‰å·²ä¿ç•™: {current_reserved / (1024**3):.2f} GB") 
                    print(f"ä¼°è®¡å¯ç”¨: {free_memory / (1024**3):.2f} GB")
                    
                    # å°è¯•åˆ†é…æ¯”å¯ç”¨å†…å­˜å¤§å¾ˆå¤šçš„å†…å­˜
                    oom_size_bytes = int(free_memory * 3)  # 3å€äºå¯ç”¨å†…å­˜
                    oom_size_mb = oom_size_bytes // (1024 * 1024)
                    
                    print(f"\n>> å°è¯•åˆ†é…è¶…å¤§å†…å­˜å—: {oom_size_mb}MB ({oom_size_bytes / (1024**3):.2f} GB)")
                    print(">> é¢„æœŸæ­¤æ“ä½œå°†å¤±è´¥å¹¶äº§ç”ŸOOMé”™è¯¯...")
                    
                    print_stack()  # æ‰“å°è°ƒç”¨æ ˆ
                    print_memory_stats("OOMæµ‹è¯•å‰")
                    
                    # è¿™åº”è¯¥ä¼šå¤±è´¥
                    oom_tensor = torch.ones(oom_size_bytes // 4, device='cuda', dtype=torch.float32)
                    print("âš ï¸  è­¦å‘Š: è¶…å¤§å†…å­˜åˆ†é…ç«Ÿç„¶æˆåŠŸäº†ï¼è¿™å¯èƒ½è¡¨æ˜æ˜¾å­˜æ£€æµ‹æœ‰è¯¯")
                    leaked_tensors.append(oom_tensor)
                    
                except RuntimeError as e:
                    print(f"âœ“ é¢„æœŸçš„OOMé”™è¯¯å‘ç”Ÿ: {str(e)}")
                    if "out of memory" in str(e).lower():
                        print("âœ“ ç¡®è®¤è¿™æ˜¯æ˜¾å­˜ä¸è¶³é”™è¯¯")
                        
                        # å°è¯•è·å–è¯¦ç»†çš„CUDAé”™è¯¯ä¿¡æ¯
                        try:
                            print(f"CUDAæœ€åé”™è¯¯: {torch.cuda.get_device_name(0)}")
                            print(f"CUDAå†…å­˜ä½¿ç”¨æƒ…å†µ:")
                            print(f"  åˆ†é…çš„å†…å­˜: {torch.cuda.memory_allocated() / (1024**3):.2f} GB")
                            print(f"  ç¼“å­˜çš„å†…å­˜: {torch.cuda.memory_reserved() / (1024**3):.2f} GB")
                        except:
                            pass
                    else:
                        print(f"âœ— æ„å¤–çš„é”™è¯¯ç±»å‹: {str(e)}")
                        
                except Exception as e:
                    print(f"âœ— æ„å¤–çš„å¼‚å¸¸: {str(e)}")
                    traceback.print_exc()
                
                finally:
                    print_memory_stats("OOMæµ‹è¯•å")
                    last_oom_time = current_time
                    print(f"{'='*60}")
            
            # è®°å½•ç»Ÿè®¡ä¿¡æ¯
            if allocation_counter % 100 == 0:
                elapsed_minutes = elapsed_time / 60
                remaining_minutes = duration_minutes - elapsed_minutes
                total_leaked_memory = sum(t.numel() * t.element_size() for t in leaked_tensors)
                
                print(f"\n{'*'*60}")
                print(f"[è¿›åº¦æŠ¥å‘Š] åˆ†é…æ¬¡æ•°: {allocation_counter}")
                print(f"[è¿›åº¦æŠ¥å‘Š] å·²ç”¨æ—¶é—´: {elapsed_minutes:.1f} åˆ†é’Ÿ")
                print(f"[è¿›åº¦æŠ¥å‘Š] å‰©ä½™æ—¶é—´: {remaining_minutes:.1f} åˆ†é’Ÿ")
                print(f"[è¿›åº¦æŠ¥å‘Š] æ³„æ¼å¼ é‡æ•°: {len(leaked_tensors)}")
                print(f"[è¿›åº¦æŠ¥å‘Š] ä¼°è®¡æ³„æ¼å†…å­˜: {total_leaked_memory / (1024**3):.2f} GB")
                print_memory_stats("è¿›åº¦æŠ¥å‘Š")
                print(f"{'*'*60}")
            
            # çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…è¿‡äºé¢‘ç¹çš„åˆ†é…
            time.sleep(0.1)
            
    except KeyboardInterrupt:
        print(f"\nç”¨æˆ·ä¸­æ–­æµ‹è¯• (Ctrl+C)")
        
    except Exception as e:
        print(f"\næµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿæ„å¤–é”™è¯¯: {str(e)}")
        traceback.print_exc()
        
    finally:
        # æµ‹è¯•ç»“æŸç»Ÿè®¡
        end_time = time.time()
        total_duration = end_time - start_time
        total_leaked_memory = sum(t.numel() * t.element_size() for t in leaked_tensors) if leaked_tensors else 0
        
        print(f"\n{'='*80}")
        print(f"å†…å­˜æ³„æ¼å’ŒOOMæµ‹è¯•å®Œæˆ")
        print(f"{'='*80}")
        print(f"æ€»æµ‹è¯•æ—¶é—´: {total_duration / 60:.2f} åˆ†é’Ÿ")
        print(f"æ€»åˆ†é…æ¬¡æ•°: {allocation_counter}")
        print(f"æœ€ç»ˆæ³„æ¼å¼ é‡æ•°: {len(leaked_tensors)}")
        print(f"æœ€ç»ˆä¼°è®¡æ³„æ¼å†…å­˜: {total_leaked_memory / (1024**3):.2f} GB")
        print_memory_stats("æµ‹è¯•ç»“æŸæ—¶")
        
        # è¯¢é—®æ˜¯å¦æ¸…ç†å†…å­˜
        print(f"\næ³¨æ„: å½“å‰æœ‰ {len(leaked_tensors)} ä¸ªå¼ é‡æœªé‡Šæ”¾")
        print(f"è¿™äº›å¼ é‡å°†åœ¨ç¨‹åºç»“æŸæ—¶è‡ªåŠ¨é‡Šæ”¾")
        print(f"å¦‚éœ€æ‰‹åŠ¨æ¸…ç†ï¼Œå¯ä»¥è°ƒç”¨ torch.cuda.empty_cache()")

def test_fragmentation_pattern():
    """
    ä¸“é—¨æµ‹è¯•æ˜¾å­˜ç¢ç‰‡åŒ–æ¨¡å¼
    é€šè¿‡å¤šè½®åˆ†é…å’Œé‡Šæ”¾ä¸è§„åˆ™å¤§å°çš„å†…å­˜å—æ¥åˆ¶é€ æ›´ä¸¥é‡çš„ç¢ç‰‡åŒ–
    """
    print(f"\n===== å¼€å§‹æ˜¾å­˜ç¢ç‰‡åŒ–æ¨¡å¼æµ‹è¯• =====")
    
    all_tensors = []
    fragmentation_rounds = 50  # å¢åŠ ç¢ç‰‡åŒ–è½®æ•°
    
    try:
        # è·å–GPUæ€»å†…å­˜ä¿¡æ¯
        if torch.cuda.is_available():
            gpu_properties = torch.cuda.get_device_properties(0)
            total_memory = gpu_properties.total_memory
            print(f"GPUæ€»å†…å­˜: {total_memory / (1024**3):.2f} GB")
        
        for round_num in range(fragmentation_rounds):
            print(f"\n{'='*70}")
            print(f"ç¬¬ {round_num + 1}/{fragmentation_rounds} è½®ç¢ç‰‡åŒ–æµ‹è¯•")
            print(f"{'='*70}")
            
            # ç¬¬ä¸€é˜¶æ®µï¼šåˆ†é…å„ç§å¤§å°çš„å†…å­˜å—
            print(f"\n>> ç¬¬ä¸€é˜¶æ®µ: åˆ†é…ä¸è§„åˆ™å¤§å°çš„å†…å­˜å— (è½®æ¬¡ {round_num + 1})")
            
            # æ¯è½®ä½¿ç”¨ä¸åŒçš„å¤§å°æ¨¡å¼
            if round_num == 0:
                # ç¬¬ä¸€è½®ï¼šè¾ƒå¤§çš„ä¸è§„åˆ™å—
                sizes_mb = [5, 12, 28, 65, 134, 257, 512, 789, 1024]
            elif round_num == 1:
                # ç¬¬äºŒè½®ï¼šä¸­ç­‰å¤§å°çš„å—
                sizes_mb = [3, 7, 15, 31, 63, 127, 255, 378, 501]
            elif round_num == 2:
                # ç¬¬ä¸‰è½®ï¼šå°å—æ··åˆ
                sizes_mb = [1, 2, 4, 8, 16, 32, 64, 128, 256]
            elif round_num == 3:
                # ç¬¬å››è½®ï¼šéšæœºå¤§å°
                sizes_mb = [np.random.randint(1, 200) for _ in range(12)]
            else:
                # ç¬¬äº”è½®ï¼šæå…¶ä¸è§„åˆ™çš„å¤§å°
                sizes_mb = [1, 3, 9, 27, 81, 243, 45, 135, 405, 89, 267, 801]
            
            print(f"æœ¬è½®å°†åˆ†é…çš„å†…å­˜å—å¤§å°: {sizes_mb} MB")
            
            round_tensors = []  # å½“å‰è½®æ¬¡çš„å¼ é‡
            
            for i, size_mb in enumerate(sizes_mb):
                try:
                    print(f"  [è½®æ¬¡{round_num+1}] åˆ†é…å†…å­˜å— {i+1}/{len(sizes_mb)}: {size_mb}MB")
                    print_stack()
                    print_memory_stats(f"è½®æ¬¡{round_num+1}åˆ†é…å—{i+1}å‰")
                    
                    tensor = torch.ones((size_mb * 256, 1024), device='cuda', dtype=torch.float32)
                    tensor_info = (f"round{round_num+1}_block_{i+1}_{size_mb}MB", tensor)
                    all_tensors.append(tensor_info)
                    round_tensors.append(tensor_info)
                    
                    print_memory_stats(f"è½®æ¬¡{round_num+1}åˆ†é…å—{i+1}å")
                    print(f"  âœ“ æˆåŠŸåˆ†é…ï¼Œå½“å‰æ€»å¼ é‡æ•°: {len(all_tensors)}")
                    
                    # æ·»åŠ å»¶è¿Ÿï¼Œä¾¿äºè§‚å¯Ÿ
                    time.sleep(0.2)
                    
                except RuntimeError as e:
                    print(f"  âœ— åˆ†é…å¤±è´¥: {e}")
                    if "out of memory" in str(e).lower():
                        print(f"  æ˜¾å­˜ä¸è¶³ï¼Œåœæ­¢å½“å‰è½®æ¬¡çš„åˆ†é…")
                        break
                    
            print(f"\nè½®æ¬¡ {round_num + 1} åˆ†é…é˜¶æ®µå®Œæˆï¼ŒæˆåŠŸåˆ†é… {len(round_tensors)} ä¸ªå†…å­˜å—")
            print_memory_stats(f"è½®æ¬¡{round_num+1}åˆ†é…å®Œæˆ")
            
            # ç¬¬äºŒé˜¶æ®µï¼šæœ‰ç­–ç•¥åœ°é‡Šæ”¾å†…å­˜å—ï¼Œåˆ¶é€ ç¢ç‰‡
            print(f"\n>> ç¬¬äºŒé˜¶æ®µ: æœ‰ç­–ç•¥åœ°é‡Šæ”¾å†…å­˜å—åˆ¶é€ ç¢ç‰‡ (è½®æ¬¡ {round_num + 1})")
            
            if len(round_tensors) > 0:
                # ä½¿ç”¨ä¸åŒçš„é‡Šæ”¾ç­–ç•¥
                if round_num % 3 == 0:
                    # ç­–ç•¥1ï¼šé‡Šæ”¾å¥‡æ•°ä½ç½®çš„å—
                    indices_to_free = [i for i in range(len(round_tensors)) if i % 2 == 1]
                    strategy_name = "å¥‡æ•°ä½ç½®é‡Šæ”¾"
                elif round_num % 3 == 1:
                    # ç­–ç•¥2ï¼šé‡Šæ”¾ä¸­é—´éƒ¨åˆ†çš„å—
                    start = len(round_tensors) // 4
                    end = 3 * len(round_tensors) // 4
                    indices_to_free = list(range(start, end))
                    strategy_name = "ä¸­é—´éƒ¨åˆ†é‡Šæ”¾"
                else:
                    # ç­–ç•¥3ï¼šéšæœºé‡Šæ”¾60%çš„å—
                    num_to_free = int(len(round_tensors) * 0.6)
                    indices_to_free = np.random.choice(len(round_tensors), num_to_free, replace=False).tolist()
                    strategy_name = "éšæœº60%é‡Šæ”¾"
                
                print(f"  ä½¿ç”¨ç­–ç•¥: {strategy_name}")
                print(f"  å°†é‡Šæ”¾ {len(indices_to_free)}/{len(round_tensors)} ä¸ªå†…å­˜å—")
                
                # æ‰§è¡Œé‡Šæ”¾
                freed_count = 0
                for idx in sorted(indices_to_free, reverse=True):
                    if idx < len(round_tensors):
                        name, tensor = round_tensors[idx]
                        print(f"    [è½®æ¬¡{round_num+1}] é‡Šæ”¾ {name}")
                        
                        # ä»æ€»åˆ—è¡¨ä¸­ç§»é™¤
                        all_tensors = [(n, t) for n, t in all_tensors if n != name]
                        
                        del tensor
                        round_tensors.pop(idx)
                        freed_count += 1
                        
                        # æ¯é‡Šæ”¾å‡ ä¸ªå—å°±æ¸…ç©ºä¸€æ¬¡ç¼“å­˜
                        if freed_count % 3 == 0:
                            torch.cuda.empty_cache()
                            print_memory_stats(f"è½®æ¬¡{round_num+1}é‡Šæ”¾{freed_count}ä¸ªå—å")
                        
                        time.sleep(0.1)  # çŸ­æš‚å»¶è¿Ÿ
                
                print(f"  è½®æ¬¡ {round_num + 1} é‡Šæ”¾é˜¶æ®µå®Œæˆï¼Œé‡Šæ”¾äº† {freed_count} ä¸ªå†…å­˜å—")
                print(f"  å‰©ä½™å¼ é‡æ•°: {len(all_tensors)}")
                print_memory_stats(f"è½®æ¬¡{round_num+1}é‡Šæ”¾å®Œæˆ")
            
            # ç¬¬ä¸‰é˜¶æ®µï¼šåœ¨ç¢ç‰‡åŒ–å†…å­˜ä¸­å°è¯•åˆ†é…æ–°çš„è¿ç»­å¤§å—
            print(f"\n>> ç¬¬ä¸‰é˜¶æ®µ: åœ¨ç¢ç‰‡åŒ–å†…å­˜ä¸­æµ‹è¯•å¤§å—åˆ†é… (è½®æ¬¡ {round_num + 1})")
            
            test_sizes = [200, 350, 500, 750, 1000]  # æµ‹è¯•ä¸åŒå¤§å°çš„è¿ç»­åˆ†é…
            successful_allocations = 0
            
            for test_size in test_sizes:
                try:
                    print(f"    å°è¯•åˆ†é…è¿ç»­å¤§å—: {test_size}MB")
                    print_memory_stats(f"å¤§å—åˆ†é…{test_size}MBå‰")
                    
                    test_tensor = torch.ones((test_size * 256, 1024), device='cuda', dtype=torch.float32)
                    all_tensors.append((f"round{round_num+1}_test_block_{test_size}MB", test_tensor))
                    successful_allocations += 1
                    
                    print(f"    âœ“ æˆåŠŸåˆ†é… {test_size}MB è¿ç»­å—")
                    print_memory_stats(f"å¤§å—åˆ†é…{test_size}MBå")
                    
                except RuntimeError as e:
                    print(f"    âœ— åˆ†é… {test_size}MB å¤±è´¥: {e}")
                    if "out of memory" in str(e).lower():
                        print(f"    å¯èƒ½ç”±äºç¢ç‰‡åŒ–å¯¼è‡´æ— æ³•åˆ†é… {test_size}MB è¿ç»­å†…å­˜")
                    break
            
            print(f"  è½®æ¬¡ {round_num + 1} å¤§å—åˆ†é…æµ‹è¯•å®Œæˆï¼ŒæˆåŠŸåˆ†é… {successful_allocations}/{len(test_sizes)} ä¸ªå¤§å—")
            
            # è½®æ¬¡é—´çš„å†…å­˜çŠ¶æ€æŠ¥å‘Š
            if len(all_tensors) > 0:
                total_allocated = sum(t.numel() * t.element_size() for _, t in all_tensors)
                print(f"\nè½®æ¬¡ {round_num + 1} å®Œæˆ:")
                print(f"  å½“å‰å¼ é‡æ€»æ•°: {len(all_tensors)}")
                print(f"  ä¼°è®¡å ç”¨å†…å­˜: {total_allocated / (1024**3):.2f} GB")
                print_memory_stats(f"è½®æ¬¡{round_num+1}ç»“æŸ")
            
            # è½®æ¬¡é—´å»¶è¿Ÿ
            if round_num < fragmentation_rounds - 1:
                print(f"\nç­‰å¾… 2 ç§’åå¼€å§‹ä¸‹ä¸€è½®...")
                time.sleep(2)
        
        # æœ€ç»ˆç¢ç‰‡åŒ–æ•ˆæœæµ‹è¯•
        print(f"\n{'='*80}")
        print(f"æœ€ç»ˆç¢ç‰‡åŒ–æ•ˆæœæµ‹è¯•")
        print(f"{'='*80}")
        
        print(f"\n>> æœ€ç»ˆæµ‹è¯•: å°è¯•åˆ†é…å„ç§å¤§å°çš„å†…å­˜å—")
        final_test_sizes = [50, 100, 200, 400, 800, 1200, 1600, 2000]
        final_success_count = 0
        
        for size in final_test_sizes:
            try:
                print(f"  æœ€ç»ˆæµ‹è¯•åˆ†é…: {size}MB")
                final_tensor = torch.ones((size * 256, 1024), device='cuda', dtype=torch.float32)
                all_tensors.append((f"final_test_{size}MB", final_tensor))
                final_success_count += 1
                print(f"  âœ“ æˆåŠŸ")
                print_memory_stats(f"æœ€ç»ˆæµ‹è¯•{size}MBå")
            except RuntimeError as e:
                print(f"  âœ— å¤±è´¥: {e}")
                if "out of memory" in str(e).lower():
                    print(f"  ç¢ç‰‡åŒ–å¯¼è‡´æ— æ³•åˆ†é… {size}MB è¿ç»­å†…å­˜")
                break
        
        print(f"\næœ€ç»ˆåˆ†é…æµ‹è¯•ç»“æœ: {final_success_count}/{len(final_test_sizes)} æˆåŠŸ")
        
        # ç¢ç‰‡åŒ–åˆ†ææŠ¥å‘Š
        print(f"\n{'='*80}")
        print(f"ç¢ç‰‡åŒ–åˆ†ææŠ¥å‘Š")
        print(f"{'='*80}")
        
        if len(all_tensors) > 0:
            total_tensors = len(all_tensors)
            total_memory = sum(t.numel() * t.element_size() for _, t in all_tensors)
            avg_size = total_memory / total_tensors if total_tensors > 0 else 0
            
            # æŒ‰å¤§å°åˆ†ç±»ç»Ÿè®¡
            small_blocks = sum(1 for _, t in all_tensors if t.numel() * t.element_size() < 50 * 1024 * 1024)
            medium_blocks = sum(1 for _, t in all_tensors if 50 * 1024 * 1024 <= t.numel() * t.element_size() < 200 * 1024 * 1024)
            large_blocks = sum(1 for _, t in all_tensors if t.numel() * t.element_size() >= 200 * 1024 * 1024)
            
            print(f"æ€»å¼ é‡æ•°é‡: {total_tensors}")
            print(f"æ€»å†…å­˜ä½¿ç”¨: {total_memory / (1024**3):.2f} GB")
            print(f"å¹³å‡å—å¤§å°: {avg_size / (1024**2):.2f} MB")
            print(f"å†…å­˜å—åˆ†å¸ƒ:")
            print(f"  å°å— (<50MB): {small_blocks} ä¸ª ({small_blocks/total_tensors*100:.1f}%)")
            print(f"  ä¸­å— (50-200MB): {medium_blocks} ä¸ª ({medium_blocks/total_tensors*100:.1f}%)")
            print(f"  å¤§å— (>200MB): {large_blocks} ä¸ª ({large_blocks/total_tensors*100:.1f}%)")
            
            print(f"\nç¢ç‰‡åŒ–ç¨‹åº¦è¯„ä¼°:")
            if small_blocks / total_tensors > 0.6:
                print("  ğŸ”´ ä¸¥é‡ç¢ç‰‡åŒ– - å°å—å æ¯”è¶…è¿‡60%")
            elif small_blocks / total_tensors > 0.4:
                print("  ğŸŸ¡ ä¸­ç­‰ç¢ç‰‡åŒ– - å°å—å æ¯”åœ¨40-60%")
            else:
                print("  ğŸŸ¢ è½»åº¦ç¢ç‰‡åŒ– - å°å—å æ¯”ä½äº40%")
                
    except Exception as e:
        print(f"\nç¢ç‰‡åŒ–æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        traceback.print_exc()
        
    finally:
        # æ¸…ç†æ‰€æœ‰å‰©ä½™å†…å­˜
        print(f"\n{'='*80}")
        print(f"æ¸…ç†é˜¶æ®µ: é‡Šæ”¾æ‰€æœ‰å‰©ä½™å†…å­˜")
        print(f"{'='*80}")
        
        cleanup_count = 0
        for name, tensor in all_tensors:
            print(f"æ¸…ç† {name}")
            del tensor
            cleanup_count += 1
            
            # æ¯æ¸…ç†10ä¸ªå¼ é‡æ‰“å°ä¸€æ¬¡çŠ¶æ€
            if cleanup_count % 10 == 0:
                torch.cuda.empty_cache()
                print_memory_stats(f"æ¸…ç†{cleanup_count}ä¸ªå¼ é‡å")
        
        all_tensors.clear()
        
        # æœ€ç»ˆæ¸…ç†
        gc.collect()
        torch.cuda.empty_cache()
        print_memory_stats("æœ€ç»ˆæ¸…ç†å®Œæˆå")
        
        print(f"ç¢ç‰‡åŒ–æµ‹è¯•å®Œæˆï¼Œå…±æ¸…ç†äº† {cleanup_count} ä¸ªå¼ é‡")
        
def test_fragmentation_pattern1():
    """
    ä¸“é—¨æµ‹è¯•æ˜¾å­˜ç¢ç‰‡åŒ–æ¨¡å¼
    é€šè¿‡å¤šè½®åˆ†é…å’Œé‡Šæ”¾ä¸è§„åˆ™å¤§å°çš„å†…å­˜å—æ¥åˆ¶é€ æ›´ä¸¥é‡çš„ç¢ç‰‡åŒ–
    å¢å¼ºç‰ˆï¼šåˆ›é€ æ›´å¤šå¤§å—ç©ºéš™ä»¥ä¾¿å¯è§†åŒ–
    """
    print(f"\n===== å¼€å§‹æ˜¾å­˜ç¢ç‰‡åŒ–æ¨¡å¼æµ‹è¯• (å¢å¼ºç‰ˆ) =====")
    
    all_tensors = []
    fragmentation_rounds = 200  # å‡å°‘è½®æ•°ä½†å¢åŠ æ¯è½®çš„å¤æ‚åº¦
    
    try:
        # è·å–GPUæ€»å†…å­˜ä¿¡æ¯
        if torch.cuda.is_available():
            gpu_properties = torch.cuda.get_device_properties(0)
            total_memory = gpu_properties.total_memory
            print(f"GPUæ€»å†…å­˜: {total_memory / (1024**3):.2f} GB")
        
        for round_num in range(fragmentation_rounds):
            print(f"\n{'='*70}")
            print(f"ç¬¬ {round_num + 1}/{fragmentation_rounds} è½®ç¢ç‰‡åŒ–æµ‹è¯•")
            print(f"{'='*70}")
            
            # ç¬¬ä¸€é˜¶æ®µï¼šåˆ†é…å„ç§å¤§å°çš„å†…å­˜å—ï¼Œç‰¹åˆ«å¢åŠ å¤§å—
            print(f"\n>> ç¬¬ä¸€é˜¶æ®µ: åˆ†é…ä¸è§„åˆ™å¤§å°çš„å†…å­˜å— (è½®æ¬¡ {round_num + 1})")
            
            # æ¯è½®ä½¿ç”¨ä¸åŒçš„å¤§å°æ¨¡å¼ï¼Œç‰¹åˆ«åŠ å¼ºå¤§å—åˆ†é…
            if round_num == 0:
                # ç¬¬ä¸€è½®ï¼šå¤§é‡å¤§å— + å°‘é‡å°å—
                sizes_mb = [512, 1024, 768, 256, 512, 384, 896, 1280, 640, 5, 12, 28]
            elif round_num == 1:
                # ç¬¬äºŒè½®ï¼šè¶…å¤§å— + ä¸­å—
                sizes_mb = [1536, 2048, 1024, 512, 768, 1280, 15, 31, 63, 127]
            elif round_num == 2:
                # ç¬¬ä¸‰è½®ï¼šå¤§ä¸­å°æ··åˆï¼Œä½†ä»¥å¤§å—ä¸ºä¸»
                sizes_mb = [800, 1200, 400, 600, 1000, 200, 8, 16, 32, 64]
            elif round_num == 3:
                # ç¬¬å››è½®ï¼šæå¤§å—
                sizes_mb = [2048, 1536, 2560, 1792, 1024, 3, 7, 15]
            elif round_num == 4:
                # ç¬¬äº”è½®ï¼šåˆ›å»º"æ¡çº¹"æ¨¡å¼ - å¤§å—é—´éš”å°å—
                sizes_mb = [1024, 5, 1024, 10, 1024, 15, 1024, 20, 1024]
            else:
                # å…¶ä»–è½®æ¬¡ï¼šéšæœºä½†åå‘å¤§å—
                large_blocks = [np.random.randint(500, 2000) for _ in range(6)]  # å¤§å—
                medium_blocks = [np.random.randint(100, 500) for _ in range(4)]   # ä¸­å—
                small_blocks = [np.random.randint(1, 50) for _ in range(3)]       # å°å—
                sizes_mb = large_blocks + medium_blocks + small_blocks
                np.random.shuffle(sizes_mb)  # éšæœºæ‰“ä¹±é¡ºåº
            
            print(f"æœ¬è½®å°†åˆ†é…çš„å†…å­˜å—å¤§å°: {sizes_mb} MB")
            
            round_tensors = []  # å½“å‰è½®æ¬¡çš„å¼ é‡
            
            for i, size_mb in enumerate(sizes_mb):
                try:
                    print(f"  [è½®æ¬¡{round_num+1}] åˆ†é…å†…å­˜å— {i+1}/{len(sizes_mb)}: {size_mb}MB")
                    print_stack()
                    print_memory_stats(f"è½®æ¬¡{round_num+1}åˆ†é…å—{i+1}å‰")
                    
                    tensor = torch.ones((size_mb * 256, 1024), device='cuda', dtype=torch.float32)
                    tensor_info = (f"round{round_num+1}_block_{i+1}_{size_mb}MB", tensor)
                    all_tensors.append(tensor_info)
                    round_tensors.append(tensor_info)
                    
                    print_memory_stats(f"è½®æ¬¡{round_num+1}åˆ†é…å—{i+1}å")
                    print(f"  âœ“ æˆåŠŸåˆ†é…ï¼Œå½“å‰æ€»å¼ é‡æ•°: {len(all_tensors)}")
                    
                    # æ·»åŠ å»¶è¿Ÿï¼Œä¾¿äºè§‚å¯Ÿ
                    time.sleep(0.2)
                    
                except RuntimeError as e:
                    print(f"  âœ— åˆ†é…å¤±è´¥: {e}")
                    if "out of memory" in str(e).lower():
                        print(f"  æ˜¾å­˜ä¸è¶³ï¼Œåœæ­¢å½“å‰è½®æ¬¡çš„åˆ†é…")
                        break
                    
            print(f"\nè½®æ¬¡ {round_num + 1} åˆ†é…é˜¶æ®µå®Œæˆï¼ŒæˆåŠŸåˆ†é… {len(round_tensors)} ä¸ªå†…å­˜å—")
            print_memory_stats(f"è½®æ¬¡{round_num+1}åˆ†é…å®Œæˆ")
            
            # ç¬¬äºŒé˜¶æ®µï¼šæˆ˜ç•¥æ€§é‡Šæ”¾å¤§å—ä»¥åˆ›é€ å¤§ç©ºéš™
            print(f"\n>> ç¬¬äºŒé˜¶æ®µ: æˆ˜ç•¥æ€§é‡Šæ”¾å¤§å—åˆ¶é€ å¤§ç©ºéš™ (è½®æ¬¡ {round_num + 1})")
            
            if len(round_tensors) > 0:
                # ä¸åŒçš„å¤§å—é‡Šæ”¾ç­–ç•¥
                if round_num % 4 == 0:
                    # ç­–ç•¥1ï¼šä¼˜å…ˆé‡Šæ”¾æœ€å¤§çš„å—
                    tensor_sizes = [(i, int(name.split('_')[-1].replace('MB', ''))) 
                                   for i, (name, _) in enumerate(round_tensors)]
                    tensor_sizes.sort(key=lambda x: x[1], reverse=True)  # æŒ‰å¤§å°é™åº
                    indices_to_free = [x[0] for x in tensor_sizes[:len(tensor_sizes)//2]]  # é‡Šæ”¾æœ€å¤§çš„ä¸€åŠ
                    strategy_name = "é‡Šæ”¾æœ€å¤§çš„å—"
                    
                elif round_num % 4 == 1:
                    # ç­–ç•¥2ï¼šé‡Šæ”¾é—´éš”çš„å¤§å—ï¼ˆåˆ›é€ å‡åŒ€ç©ºéš™ï¼‰
                    large_block_indices = []
                    for i, (name, tensor) in enumerate(round_tensors):
                        size_mb = int(name.split('_')[-1].replace('MB', ''))
                        if size_mb >= 200:  # è®¤ä¸ºæ˜¯å¤§å—
                            large_block_indices.append(i)
                    # é‡Šæ”¾æ¯éš”ä¸€ä¸ªå¤§å—
                    indices_to_free = [large_block_indices[i] for i in range(0, len(large_block_indices), 2)]
                    strategy_name = "é—´éš”é‡Šæ”¾å¤§å—"
                    
                elif round_num % 4 == 2:
                    # ç­–ç•¥3ï¼šé‡Šæ”¾ä¸­é—´å¤§å°çš„å—ï¼Œä¿ç•™æœ€å¤§å’Œæœ€å°çš„
                    tensor_sizes = [(i, int(name.split('_')[-1].replace('MB', ''))) 
                                   for i, (name, _) in enumerate(round_tensors)]
                    tensor_sizes.sort(key=lambda x: x[1])  # æŒ‰å¤§å°å‡åº
                    # é‡Šæ”¾ä¸­é—´éƒ¨åˆ†çš„å—
                    start_idx = len(tensor_sizes) // 4
                    end_idx = 3 * len(tensor_sizes) // 4
                    indices_to_free = [tensor_sizes[i][0] for i in range(start_idx, end_idx)]
                    strategy_name = "é‡Šæ”¾ä¸­ç­‰å¤§å°å—"
                    
                else:
                    # ç­–ç•¥4ï¼šåˆ›å»º"æ£‹ç›˜"æ¨¡å¼ - æŒ‰ä½ç½®é—´éš”é‡Šæ”¾
                    indices_to_free = [i for i in range(len(round_tensors)) if i % 3 == 1]
                    strategy_name = "æ£‹ç›˜æ¨¡å¼é‡Šæ”¾"
                
                print(f"  ä½¿ç”¨ç­–ç•¥: {strategy_name}")
                print(f"  å°†é‡Šæ”¾ {len(indices_to_free)}/{len(round_tensors)} ä¸ªå†…å­˜å—")
                
                # è®¡ç®—å°†è¦é‡Šæ”¾çš„å†…å­˜å¤§å°
                total_to_free_mb = 0
                for idx in indices_to_free:
                    if idx < len(round_tensors):
                        name = round_tensors[idx][0]
                        size_mb = int(name.split('_')[-1].replace('MB', ''))
                        total_to_free_mb += size_mb
                
                print(f"  å°†é‡Šæ”¾æ€»è®¡çº¦ {total_to_free_mb} MB å†…å­˜")
                
                # æ‰§è¡Œé‡Šæ”¾
                freed_count = 0
                freed_mb = 0
                for idx in sorted(indices_to_free, reverse=True):
                    if idx < len(round_tensors):
                        name, tensor = round_tensors[idx]
                        size_mb = int(name.split('_')[-1].replace('MB', ''))
                        print(f"    [è½®æ¬¡{round_num+1}] é‡Šæ”¾ {name} ({size_mb}MB)")
                        
                        # ä»æ€»åˆ—è¡¨ä¸­ç§»é™¤
                        all_tensors = [(n, t) for n, t in all_tensors if n != name]
                        
                        del tensor
                        round_tensors.pop(idx)
                        freed_count += 1
                        freed_mb += size_mb
                        
                        # æ¯é‡Šæ”¾å‡ ä¸ªå¤§å—å°±æ¸…ç©ºä¸€æ¬¡ç¼“å­˜
                        if freed_count % 2 == 0:
                            torch.cuda.empty_cache()
                            print_memory_stats(f"è½®æ¬¡{round_num+1}é‡Šæ”¾{freed_count}ä¸ªå—å")
                        
                        time.sleep(0.15)  # ç¨é•¿å»¶è¿Ÿä»¥ä¾¿è§‚å¯Ÿ
                
                print(f"  è½®æ¬¡ {round_num + 1} é‡Šæ”¾é˜¶æ®µå®Œæˆï¼Œé‡Šæ”¾äº† {freed_count} ä¸ªå†…å­˜å—ï¼Œæ€»è®¡ {freed_mb} MB")
                print(f"  å‰©ä½™å¼ é‡æ•°: {len(all_tensors)}")
                print_memory_stats(f"è½®æ¬¡{round_num+1}é‡Šæ”¾å®Œæˆ")
            
            # ç¬¬ä¸‰é˜¶æ®µï¼šåœ¨å¤§ç©ºéš™ä¸­æµ‹è¯•å„ç§å¤§å°çš„åˆ†é…
            print(f"\n>> ç¬¬ä¸‰é˜¶æ®µ: åœ¨å¤§ç©ºéš™ä¸­æµ‹è¯•åˆ†é… (è½®æ¬¡ {round_num + 1})")
            
            # æµ‹è¯•æ›´å¤šæ ·åŒ–çš„å¤§å°ï¼ŒåŒ…æ‹¬å¯èƒ½å¡«è¡¥ç©ºéš™çš„å¤§å°
            test_sizes = [50, 100, 200, 400, 600, 800, 1000, 1500, 2000, 2500]
            successful_allocations = 0
            
            for test_size in test_sizes:
                try:
                    print(f"    å°è¯•åœ¨ç©ºéš™ä¸­åˆ†é…: {test_size}MB")
                    print_memory_stats(f"ç©ºéš™åˆ†é…{test_size}MBå‰")
                    
                    test_tensor = torch.ones((test_size * 256, 1024), device='cuda', dtype=torch.float32)
                    all_tensors.append((f"round{round_num+1}_gap_fill_{test_size}MB", test_tensor))
                    successful_allocations += 1
                    
                    print(f"    âœ“ æˆåŠŸåœ¨ç©ºéš™ä¸­åˆ†é… {test_size}MB")
                    print_memory_stats(f"ç©ºéš™åˆ†é…{test_size}MBå")
                    
                    # æˆåŠŸåˆ†é…å¤§å—åç¨ä½œå»¶è¿Ÿ
                    if test_size >= 1000:
                        time.sleep(0.3)
                    
                except RuntimeError as e:
                    print(f"    âœ— ç©ºéš™åˆ†é… {test_size}MB å¤±è´¥: {e}")
                    if "out of memory" in str(e).lower():
                        print(f"    æ˜¾å­˜ä¸è¶³æˆ–ç©ºéš™ä¸å¤Ÿå¤§ï¼Œæ— æ³•åˆ†é… {test_size}MB è¿ç»­å†…å­˜")
                    break
            
            print(f"  è½®æ¬¡ {round_num + 1} ç©ºéš™åˆ†é…æµ‹è¯•å®Œæˆï¼ŒæˆåŠŸåˆ†é… {successful_allocations}/{len(test_sizes)} ä¸ªå—")
            
            # ç¬¬å››é˜¶æ®µï¼šå†æ¬¡é‡Šæ”¾ä¸€äº›åˆšåˆ†é…çš„å—ï¼Œåˆ›é€ æ–°çš„ç©ºéš™æ¨¡å¼
            if successful_allocations > 0 and round_num % 2 == 0:
                print(f"\n>> ç¬¬å››é˜¶æ®µ: å†æ¬¡é‡Šæ”¾åˆ›é€ æ–°ç©ºéš™æ¨¡å¼ (è½®æ¬¡ {round_num + 1})")
                
                # æ‰¾åˆ°åˆšåˆšåˆ†é…çš„gap_fillå—
                gap_fill_blocks = [(i, (name, tensor)) for i, (name, tensor) in enumerate(all_tensors) 
                                  if f"round{round_num+1}_gap_fill_" in name]
                
                if len(gap_fill_blocks) > 1:
                    # é‡Šæ”¾å…¶ä¸­ä¸€äº›ï¼Œåˆ›é€ æ–°çš„ç©ºéš™æ¨¡å¼
                    num_to_free = len(gap_fill_blocks) // 2
                    blocks_to_free = gap_fill_blocks[:num_to_free]
                    
                    print(f"    å°†å†æ¬¡é‡Šæ”¾ {num_to_free} ä¸ªgap_fillå—ï¼Œåˆ›é€ æ–°ç©ºéš™")
                    
                    for _, (name, tensor) in blocks_to_free:
                        size_mb = int(name.split('_')[-1].replace('MB', ''))
                        print(f"    å†æ¬¡é‡Šæ”¾ {name} ({size_mb}MB)")
                        
                        all_tensors = [(n, t) for n, t in all_tensors if n != name]
                        del tensor
                    
                    torch.cuda.empty_cache()
                    print_memory_stats(f"è½®æ¬¡{round_num+1}å†æ¬¡é‡Šæ”¾å")
            
            # è½®æ¬¡é—´çš„è¯¦ç»†å†…å­˜çŠ¶æ€æŠ¥å‘Š
            if len(all_tensors) > 0:
                total_allocated = sum(t.numel() * t.element_size() for _, t in all_tensors)
                
                # æŒ‰å¤§å°åˆ†ç±»ç»Ÿè®¡å½“å‰å†…å­˜å—
                large_blocks = sum(1 for _, t in all_tensors if t.numel() * t.element_size() >= 500 * 1024 * 1024)
                medium_blocks = sum(1 for _, t in all_tensors if 50 * 1024 * 1024 <= t.numel() * t.element_size() < 500 * 1024 * 1024)
                small_blocks = sum(1 for _, t in all_tensors if t.numel() * t.element_size() < 50 * 1024 * 1024)
                
                print(f"\nè½®æ¬¡ {round_num + 1} å®Œæˆ:")
                print(f"  å½“å‰å¼ é‡æ€»æ•°: {len(all_tensors)}")
                print(f"  ä¼°è®¡å ç”¨å†…å­˜: {total_allocated / (1024**3):.2f} GB")
                print(f"  å¤§å—(â‰¥500MB): {large_blocks} ä¸ª")
                print(f"  ä¸­å—(50-500MB): {medium_blocks} ä¸ª") 
                print(f"  å°å—(<50MB): {small_blocks} ä¸ª")
                print_memory_stats(f"è½®æ¬¡{round_num+1}ç»“æŸ")
                
                # ä¼°ç®—ç©ºéš™
                if torch.cuda.is_available():
                    allocated = torch.cuda.memory_allocated()
                    reserved = torch.cuda.memory_reserved()
                    potential_gaps = reserved - allocated
                    print(f"  æ½œåœ¨ç©ºéš™å¤§å°: {potential_gaps / (1024**3):.2f} GB")
            
            # è½®æ¬¡é—´å»¶è¿Ÿ
            if round_num < fragmentation_rounds - 1:
                print(f"\nç­‰å¾… 3 ç§’åå¼€å§‹ä¸‹ä¸€è½®...")
                time.sleep(3)
        
        # æœ€ç»ˆçŠ¶æ€å’Œç©ºéš™æµ‹è¯•
        print(f"\n{'='*80}")
        print(f"æœ€ç»ˆå¤§ç©ºéš™åˆ©ç”¨æµ‹è¯•")
        print(f"{'='*80}")
        
        print(f"\n>> æœ€ç»ˆæµ‹è¯•: å°è¯•åˆ©ç”¨å„ç§å¤§å°çš„ç©ºéš™")
        final_test_sizes = [25, 50, 100, 200, 400, 800, 1200, 1600, 2000, 2500, 3000]
        final_success_count = 0
        
        for size in final_test_sizes:
            try:
                print(f"  æœ€ç»ˆç©ºéš™æµ‹è¯•åˆ†é…: {size}MB")
                final_tensor = torch.ones((size * 256, 1024), device='cuda', dtype=torch.float32)
                all_tensors.append((f"final_gap_test_{size}MB", final_tensor))
                final_success_count += 1
                print(f"  âœ“ æˆåŠŸåˆ©ç”¨ç©ºéš™åˆ†é… {size}MB")
                print_memory_stats(f"æœ€ç»ˆç©ºéš™æµ‹è¯•{size}MBå")
            except RuntimeError as e:
                print(f"  âœ— å¤±è´¥: {e}")
                if "out of memory" in str(e).lower():
                    print(f"  ç©ºéš™ä¸è¶³ï¼Œæ— æ³•åˆ†é… {size}MB è¿ç»­å†…å­˜")
                break
        
        print(f"\næœ€ç»ˆç©ºéš™åˆ©ç”¨æµ‹è¯•ç»“æœ: {final_success_count}/{len(final_test_sizes)} æˆåŠŸ")
        
        # è¯¦ç»†çš„ç¢ç‰‡åŒ–å’Œç©ºéš™åˆ†ææŠ¥å‘Š
        print(f"\n{'='*80}")
        print(f"ç¢ç‰‡åŒ–å’Œç©ºéš™åˆ†ææŠ¥å‘Š")
        print(f"{'='*80}")
        
        if len(all_tensors) > 0:
            total_tensors = len(all_tensors)
            total_memory = sum(t.numel() * t.element_size() for _, t in all_tensors)
            avg_size = total_memory / total_tensors if total_tensors > 0 else 0
            
            # è¯¦ç»†çš„å¤§å°åˆ†ç±»ç»Ÿè®¡
            huge_blocks = sum(1 for _, t in all_tensors if t.numel() * t.element_size() >= 1000 * 1024 * 1024)  # â‰¥1GB
            large_blocks = sum(1 for _, t in all_tensors if 500 * 1024 * 1024 <= t.numel() * t.element_size() < 1000 * 1024 * 1024)  # 500MB-1GB
            medium_blocks = sum(1 for _, t in all_tensors if 100 * 1024 * 1024 <= t.numel() * t.element_size() < 500 * 1024 * 1024)  # 100-500MB
            small_blocks = sum(1 for _, t in all_tensors if 10 * 1024 * 1024 <= t.numel() * t.element_size() < 100 * 1024 * 1024)   # 10-100MB
            tiny_blocks = sum(1 for _, t in all_tensors if t.numel() * t.element_size() < 10 * 1024 * 1024)  # <10MB
            
            print(f"æ€»å¼ é‡æ•°é‡: {total_tensors}")
            print(f"æ€»å†…å­˜ä½¿ç”¨: {total_memory / (1024**3):.2f} GB")
            print(f"å¹³å‡å—å¤§å°: {avg_size / (1024**2):.2f} MB")
            print(f"è¯¦ç»†å†…å­˜å—åˆ†å¸ƒ:")
            print(f"  è¶…å¤§å— (â‰¥1GB): {huge_blocks} ä¸ª ({huge_blocks/total_tensors*100:.1f}%)")
            print(f"  å¤§å— (500MB-1GB): {large_blocks} ä¸ª ({large_blocks/total_tensors*100:.1f}%)")
            print(f"  ä¸­å— (100-500MB): {medium_blocks} ä¸ª ({medium_blocks/total_tensors*100:.1f}%)")
            print(f"  å°å— (10-100MB): {small_blocks} ä¸ª ({small_blocks/total_tensors*100:.1f}%)")
            print(f"  å¾®å— (<10MB): {tiny_blocks} ä¸ª ({tiny_blocks/total_tensors*100:.1f}%)")
            
            # GPUå†…å­˜æ•´ä½“çŠ¶æ€
            if torch.cuda.is_available():
                allocated = torch.cuda.memory_allocated()
                reserved = torch.cuda.memory_reserved()
                free_cached = reserved - allocated
                total_gpu_memory = torch.cuda.get_device_properties(0).total_memory
                free_total = total_gpu_memory - reserved
                
                print(f"\nGPUå†…å­˜çŠ¶æ€:")
                print(f"  å·²åˆ†é…å†…å­˜: {allocated / (1024**3):.2f} GB ({allocated/total_gpu_memory*100:.1f}%)")
                print(f"  å·²ä¿ç•™å†…å­˜: {reserved / (1024**3):.2f} GB ({reserved/total_gpu_memory*100:.1f}%)")
                print(f"  ç¼“å­˜ç©ºéš™: {free_cached / (1024**3):.2f} GB ({free_cached/total_gpu_memory*100:.1f}%)")
                print(f"  å®Œå…¨ç©ºé—²: {free_total / (1024**3):.2f} GB ({free_total/total_gpu_memory*100:.1f}%)")
                
                print(f"\nç©ºéš™åˆ†æ:")
                if free_cached > 1024**3:  # å¤§äº1GBçš„ç¼“å­˜ç©ºéš™
                    print("  ğŸŸ¢ å­˜åœ¨å¤§é‡ç¼“å­˜ç©ºéš™ï¼Œæœ‰åˆ©äºå¯è§†åŒ–å¤§ç©ºç™½å—")
                elif free_cached > 512*1024**2:  # å¤§äº512MB
                    print("  ğŸŸ¡ å­˜åœ¨ä¸­ç­‰ç¼“å­˜ç©ºéš™")
                else:
                    print("  ğŸ”´ ç¼“å­˜ç©ºéš™è¾ƒå°‘")
            
            print(f"\nç¢ç‰‡åŒ–ç¨‹åº¦è¯„ä¼°:")
            large_and_huge = huge_blocks + large_blocks
            if large_and_huge / total_tensors > 0.3:
                print("  ğŸŸ¢ å¤§å—æ¯”ä¾‹é«˜ï¼Œå­˜åœ¨è‰¯å¥½çš„å¤§ç©ºéš™æ½œåŠ›")
            elif tiny_blocks / total_tensors > 0.6:
                print("  ğŸ”´ ä¸¥é‡ç¢ç‰‡åŒ– - å¾®å°å—å æ¯”è¶…è¿‡60%")
            elif small_blocks / total_tensors > 0.4:
                print("  ğŸŸ¡ ä¸­ç­‰ç¢ç‰‡åŒ– - å°å—å æ¯”åœ¨40-60%")
            else:
                print("  ğŸŸ¢ è½»åº¦ç¢ç‰‡åŒ– - å¤§ä¸­å—ä¸ºä¸»")
                
    except Exception as e:
        print(f"\nç¢ç‰‡åŒ–æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        traceback.print_exc()
        
    finally:
        # åˆ†é˜¶æ®µæ¸…ç†ï¼Œä¾¿äºè§‚å¯Ÿç©ºéš™å˜åŒ–
        print(f"\n{'='*80}")
        print(f"åˆ†é˜¶æ®µæ¸…ç†é˜¶æ®µ: è§‚å¯Ÿç©ºéš™é‡Šæ”¾è¿‡ç¨‹")
        print(f"{'='*80}")
        
        if all_tensors:
            # æŒ‰å¤§å°åˆ†ç»„æ¸…ç†
            tensor_by_size = {}
            for name, tensor in all_tensors:
                size_bytes = tensor.numel() * tensor.element_size()
                if size_bytes >= 1000 * 1024 * 1024:
                    category = "huge"
                elif size_bytes >= 500 * 1024 * 1024:
                    category = "large"
                elif size_bytes >= 100 * 1024 * 1024:
                    category = "medium"
                else:
                    category = "small"
                
                if category not in tensor_by_size:
                    tensor_by_size[category] = []
                tensor_by_size[category].append((name, tensor))
            
            # åˆ†ç±»åˆ«æ¸…ç†
            cleanup_order = ["small", "medium", "large", "huge"]
            total_cleanup_count = 0
            
            for category in cleanup_order:
                if category in tensor_by_size:
                    print(f"\n>> æ¸…ç† {category} ç±»åˆ«å¼ é‡...")
                    category_count = 0
                    
                    for name, tensor in tensor_by_size[category]:
                        size_mb = tensor.numel() * tensor.element_size() / (1024 * 1024)
                        print(f"æ¸…ç† {name} ({size_mb:.1f}MB)")
                        del tensor
                        category_count += 1
                        total_cleanup_count += 1
                        
                        # æ¯æ¸…ç†å‡ ä¸ªå¼ é‡æ‰“å°ä¸€æ¬¡çŠ¶æ€
                        if category_count % 5 == 0:
                            torch.cuda.empty_cache()
                            print_memory_stats(f"æ¸…ç†{category}ç±»ç¬¬{category_count}ä¸ªå")
                    
                    torch.cuda.empty_cache()
                    print_memory_stats(f"æ¸…ç†{category}ç±»å®Œæˆ")
                    time.sleep(1)  # å»¶è¿Ÿä»¥ä¾¿è§‚å¯Ÿ
        
        all_tensors.clear()
        
        # æœ€ç»ˆæ¸…ç†
        gc.collect()
        torch.cuda.empty_cache()
        print_memory_stats("æœ€ç»ˆæ¸…ç†å®Œæˆå")
        
        print(f"å¢å¼ºç¢ç‰‡åŒ–æµ‹è¯•å®Œæˆï¼Œå…±æ¸…ç†äº† {total_cleanup_count} ä¸ªå¼ é‡")
        print("ç°åœ¨åº”è¯¥æœ‰æ›´å¤šå¤§ç©ºéš™ä¾¿äºå¯è§†åŒ–")

def test_extreme_fragmentation():
    """
    æç«¯ç¢ç‰‡åŒ–æµ‹è¯• - æ›´é•¿æ—¶é—´çš„åå¤åˆ†é…å’Œé‡Šæ”¾
    """
    print(f"\n===== å¼€å§‹æç«¯ç¢ç‰‡åŒ–æµ‹è¯• =====")
    
    all_tensors = []
    test_duration_minutes = 3  # æµ‹è¯•æŒç»­3åˆ†é’Ÿ
    start_time = time.time()
    
    allocation_counter = 0
    cycle_counter = 0
    
    try:
        print(f"æµ‹è¯•å°†æŒç»­ {test_duration_minutes} åˆ†é’Ÿ")
        print(f"å½“å‰è¿›ç¨‹ PID: {os.getpid()}")
        
        while True:
            current_time = time.time()
            elapsed_time = current_time - start_time
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ—¶é—´é™åˆ¶
            if elapsed_time > test_duration_minutes * 60:
                print(f"\næµ‹è¯•æ—¶é—´å·²è¾¾åˆ° {test_duration_minutes} åˆ†é’Ÿï¼Œç»“æŸæµ‹è¯•")
                break
            
            cycle_counter += 1
            print(f"\n--- å¼€å§‹ç¬¬ {cycle_counter} ä¸ªåˆ†é…-é‡Šæ”¾å‘¨æœŸ ---")
            
            # åŠ¨æ€è°ƒæ•´åˆ†é…ç­–ç•¥
            if cycle_counter % 4 == 1:
                # å‘¨æœŸ1ï¼šåˆ†é…å¾ˆå¤šå°å—
                sizes = [np.random.randint(1, 10) for _ in range(20)]
                strategy = "å¤§é‡å°å—"
            elif cycle_counter % 4 == 2:
                # å‘¨æœŸ2ï¼šåˆ†é…ä¸­ç­‰å—
                sizes = [np.random.randint(20, 100) for _ in range(10)]
                strategy = "ä¸­ç­‰å—"
            elif cycle_counter % 4 == 3:
                # å‘¨æœŸ3ï¼šåˆ†é…å°‘é‡å¤§å—
                sizes = [np.random.randint(100, 300) for _ in range(5)]
                strategy = "å°‘é‡å¤§å—"
            else:
                # å‘¨æœŸ4ï¼šæ··åˆå¤§å°
                sizes = [np.random.randint(1, 200) for _ in range(15)]
                strategy = "æ··åˆå¤§å°"
            
            print(f"ç­–ç•¥: {strategy}, å°†åˆ†é… {len(sizes)} ä¸ªå†…å­˜å—")
            
            # åˆ†é…é˜¶æ®µ
            cycle_tensors = []
            successful_allocations = 0
            
            for i, size_mb in enumerate(sizes):
                allocation_counter += 1
                try:
                    tensor = torch.randn((size_mb * 256, 1024), device='cuda', dtype=torch.float32)
                    tensor_info = (f"cycle{cycle_counter}_alloc{allocation_counter}_{size_mb}MB", tensor)
                    all_tensors.append(tensor_info)
                    cycle_tensors.append(tensor_info)
                    successful_allocations += 1
                    
                    if allocation_counter % 50 == 0:
                        print(f"  å·²å®Œæˆ {allocation_counter} æ¬¡åˆ†é…")
                        print_memory_stats(f"ç¬¬{allocation_counter}æ¬¡åˆ†é…å")
                        
                except RuntimeError as e:
                    if "out of memory" in str(e).lower():
                        print(f"  æ˜¾å­˜ä¸è¶³ï¼Œå‘¨æœŸ {cycle_counter} åˆ†é…é˜¶æ®µç»“æŸ")
                        break
                    else:
                        print(f"  åˆ†é…é”™è¯¯: {e}")
            
            print(f"å‘¨æœŸ {cycle_counter} åˆ†é…å®Œæˆ: {successful_allocations}/{len(sizes)} æˆåŠŸ")
            
            # é‡Šæ”¾é˜¶æ®µ - ä½¿ç”¨ä¸åŒçš„é‡Šæ”¾æ¨¡å¼
            if len(cycle_tensors) > 0:
                release_mode = cycle_counter % 5
                
                if release_mode == 0:
                    # é‡Šæ”¾æ‰€æœ‰
                    indices_to_free = list(range(len(cycle_tensors)))
                    mode_name = "å…¨éƒ¨é‡Šæ”¾"
                elif release_mode == 1:
                    # é‡Šæ”¾ä¸€åŠï¼ˆéšæœºï¼‰
                    num_to_free = len(cycle_tensors) // 2
                    indices_to_free = np.random.choice(len(cycle_tensors), num_to_free, replace=False).tolist()
                    mode_name = "éšæœºä¸€åŠé‡Šæ”¾"
                elif release_mode == 2:
                    # é‡Šæ”¾å¥‡æ•°ä½ç½®
                    indices_to_free = [i for i in range(len(cycle_tensors)) if i % 2 == 1]
                    mode_name = "å¥‡æ•°ä½ç½®é‡Šæ”¾"
                elif release_mode == 3:
                    # é‡Šæ”¾å‰ä¸‰åˆ†ä¹‹ä¸€
                    indices_to_free = list(range(len(cycle_tensors) // 3))
                    mode_name = "å‰ä¸‰åˆ†ä¹‹ä¸€é‡Šæ”¾"
                else:
                    # ä¸é‡Šæ”¾ï¼Œç´¯ç§¯ç¢ç‰‡
                    indices_to_free = []
                    mode_name = "ä¸é‡Šæ”¾ï¼ˆç´¯ç§¯ï¼‰"
                
                print(f"é‡Šæ”¾æ¨¡å¼: {mode_name}, å°†é‡Šæ”¾ {len(indices_to_free)} ä¸ªå†…å­˜å—")
                
                for idx in sorted(indices_to_free, reverse=True):
                    if idx < len(cycle_tensors):
                        name, tensor = cycle_tensors[idx]
                        all_tensors = [(n, t) for n, t in all_tensors if n != name]
                        del tensor
                        cycle_tensors.pop(idx)
                
                # å®šæœŸæ¸…ç†ç¼“å­˜
                if cycle_counter % 3 == 0:
                    torch.cuda.empty_cache()
            
            # å‘¨æœŸæ€§çŠ¶æ€æŠ¥å‘Š
            if cycle_counter % 10 == 0:
                elapsed_minutes = elapsed_time / 60
                remaining_minutes = test_duration_minutes - elapsed_minutes
                total_leaked_memory = sum(t.numel() * t.element_size() for _, t in all_tensors) if all_tensors else 0
                
                print(f"\n{'*'*60}")
                print(f"[æç«¯ç¢ç‰‡åŒ–è¿›åº¦] å‘¨æœŸ: {cycle_counter}")
                print(f"[æç«¯ç¢ç‰‡åŒ–è¿›åº¦] å·²ç”¨æ—¶é—´: {elapsed_minutes:.1f} åˆ†é’Ÿ")
                print(f"[æç«¯ç¢ç‰‡åŒ–è¿›åº¦] å‰©ä½™æ—¶é—´: {remaining_minutes:.1f} åˆ†é’Ÿ")
                print(f"[æç«¯ç¢ç‰‡åŒ–è¿›åº¦] ç´¯ç§¯å¼ é‡: {len(all_tensors)}")
                print(f"[æç«¯ç¢ç‰‡åŒ–è¿›åº¦] ç´¯ç§¯å†…å­˜: {total_leaked_memory / (1024**3):.2f} GB")
                print_memory_stats("æç«¯ç¢ç‰‡åŒ–è¿›åº¦")
                print(f"{'*'*60}")
            
            # çŸ­æš‚å»¶è¿Ÿ
            time.sleep(0.05)
    
    except Exception as e:
        print(f"æç«¯ç¢ç‰‡åŒ–æµ‹è¯•å‘ç”Ÿé”™è¯¯: {e}")
        traceback.print_exc()
    
    finally:
        print(f"\næç«¯ç¢ç‰‡åŒ–æµ‹è¯•æ¸…ç†...")
        for name, tensor in all_tensors:
            del tensor
        all_tensors.clear()
        gc.collect()
        torch.cuda.empty_cache()
        print_memory_stats("æç«¯ç¢ç‰‡åŒ–æµ‹è¯•æ¸…ç†å®Œæˆ")
        
def main():
    """è¿è¡Œå†…å­˜åˆ†é…æµ‹è¯•"""
    for cycle in range(200):
        try:
            mp.set_start_method('spawn', force=True)
            print("\n===== åˆ›å»ºå°æ¨¡å‹ =====")
            small_model = create_model_with_buffers(complexity=2)
            train_for_iterations(small_model, iterations=3)
            # test_large_model_transfers()
            test_custom_cuda_operations()
            # run_multiprocess_test(num_processes=3, size_mb=50, iterations=5, delay=0.5)
            # test_error_cuda_operations()
            # test_explicit_cuda_api_calls()
            
            # é‡Šæ”¾å°æ¨¡å‹
            print("\n===== é‡Šæ”¾å°æ¨¡å‹ =====")
            print_memory_stats("é‡Šæ”¾å°æ¨¡å‹å‰")
            del small_model
            gc.collect()
            torch.cuda.empty_cache()
            print_memory_stats("é‡Šæ”¾å°æ¨¡å‹å")
            
            # åˆ†é…å¤§é‡ä¸´æ—¶å†…å­˜ç„¶åé‡Šæ”¾
            print("\n===== å¤§é‡ä¸´æ—¶å†…å­˜åˆ†é…æµ‹è¯• =====")
            tensors = []
            for i in range(5):
                size = 50 + i * 20  # é€’å¢çš„å†…å­˜å¤§å°
                print(f"\n>> åˆ†é…ä¸´æ—¶å†…å­˜å— {i+1}: {size}MB")
                tensors.append(force_cuda_allocation(size, f"å¤§å—{i+1}"))
                time.sleep(0.5)  # çŸ­æš‚å»¶è¿Ÿ
            
            # éšæœºé¡ºåºé‡Šæ”¾å†…å­˜
            indices = list(range(len(tensors)))
            np.random.shuffle(indices)
            for idx in indices:
                print(f"\n>> é‡Šæ”¾ä¸´æ—¶å†…å­˜å— {idx+1}")
                force_cuda_free(tensors[idx], f"å¤§å—{idx+1}")
                tensors[idx] = None
                time.sleep(0.5)  # çŸ­æš‚å»¶è¿Ÿ
            
            print("\n===== åˆ›å»ºå¤§æ¨¡å‹ =====")
            large_model = create_model_with_buffers(complexity=4)
            
            # è¿è¡Œæ¨ç†æµ‹è¯•
            run_inference_tests(large_model)
            
            # è¿è¡Œè®­ç»ƒ
            train_for_iterations(large_model, iterations=4)
            
            print("\n===== æµ‹è¯•å®Œæˆ =====")
            print_memory_stats("æœ€ç»ˆçŠ¶æ€")
            
        except Exception as e:
            print(f"æµ‹è¯•è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {e}")
            traceback.print_exc()

def run_leak_test_only():
    """ä»…è¿è¡Œå†…å­˜æ³„æ¼å’ŒOOMæµ‹è¯•"""
    print(f"Python è¿›ç¨‹ PID: {os.getpid()}")
    print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")
    print("ç­‰å¾… 5 ç§’ä»¥ä¾¿é™„åŠ è·Ÿè¸ªå™¨...")
    time.sleep(5)
    
    # è¿è¡Œè¾ƒçŸ­æ—¶é—´çš„æµ‹è¯•ï¼Œä¾¿äºè§‚å¯Ÿ
    test_memory_leak_and_oom(duration_minutes=10, oom_interval_sec=20)
    
    print("å†…å­˜æ³„æ¼æµ‹è¯•å®Œæˆï¼Œç¨‹åºå³å°†é€€å‡º")

def run_fragmentation_pattern_only():   
    """ä»…è¿è¡Œæ˜¾å­˜ç¢ç‰‡åŒ–æ¨¡å¼æµ‹è¯•"""
    print(f"Python è¿›ç¨‹ PID: {os.getpid()}")
    print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")
    print("ç­‰å¾… 5 ç§’ä»¥ä¾¿é™„åŠ è·Ÿè¸ªå™¨...")
    time.sleep(5)
    test_extreme_fragmentation()
    # test_fragmentation_pattern1()

    print("æ˜¾å­˜ç¢ç‰‡åŒ–æ¨¡å¼æµ‹è¯•å®Œæˆï¼Œç¨‹åºå³å°†é€€å‡º")

if __name__ == "__main__":
    if len(sys.argv) > 1 and sys.argv[1] == "leak":
        run_leak_test_only()
    elif len(sys.argv) > 1 and sys.argv[1] == "frag":
        run_fragmentation_pattern_only()
    else:
        main()