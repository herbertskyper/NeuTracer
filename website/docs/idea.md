# 项目借鉴
[TrainCheck](https://www.usenix.org/conference/osdi25/presentation/jiang])是一个轻量级的静默异常检测框架，发表于OSDI25，专门用于主动检测深度学习训练过程中的静默错误（silent errors）。静默错误不会导致程序立即崩溃，但会在训练过程中悄无声息地产生错误结果，直到很久之后才被发现，造成大量资源浪费。TrainCheck的核心思想是捕获 AI/ML运行时的不变量，这些不变量描述的是AI/ML运行时应该始终保持关系，具体有三种类型的关系：Consistent 关系断言实体在特定上下文下应保持一致性，EventContain 关系断言子事件必须发生在父事件持续时间内，APISequence 关系定义 API 的调用顺序和共同出现关系。在论文中，作者复现了20个具有不同根本原因的真实世界静默训练错误，TRAINCHECK成功在单次训练迭代内检测出18个错误。

我们发现，TrainCheck 中并没有基于 CUDA API 层面以及系统指标层面的不变量检测，而CUDA API 层面以及系统指标层面的不变量检测是非常重要的。如果API调用顺序出现错乱，比如本应先分配显存再启动kernel，却出现反向调用，可能导致内存泄漏、非法访问甚至程序崩溃。系统指标的不变量（如GPU利用率应在训练开始时升高，训练结束后逐步降低）如果被破坏，往往意味着资源未被合理释放或存在异常阻塞，可能导致性能瓶颈、训练过程卡死或结果异常。通过对这些不变量进行检测，可以及时发现隐藏的系统级错误和性能异常，避免静默错误积累造成更大损失，提升系统的可观测性和可靠性。我们在项目中集成了 TrainCheck 框架，并基于 CUDA API 以及系统指标拓展了不变量的范围，在测试中 *额外检出5%\~10%* 违反的不变量关系。

[Strobelight](https://github.com/facebookincubator/strobelight) 是一个基于 BPF 的 GPU 可观测工具和分析框架，由Meta提出并开源，是一个在 Meta 的所有主机上运行的守护进程，既充当分析器又充当分析器编排工具。可以通过某些事件（例如 OOM 事件）触发分析。Strobelight 由多个子分析器组成。通过这些子分析器，它能够从机群中的任何主机收集各种性能分析，如 CPU 堆栈、内存快照和Python 堆栈。该框架有助于识别性能瓶颈，并优化集群的资源利用率。

我们发现，Strobelight 主要关注于在集群级别进行性能分析和优化，在多机环境中表现更优，而 NeuTracer 则需要支持单机与多机，因此，我们对 Strobelight进行拓展，通过分析CUDA API 相关异常、GPU显存泄漏以及碎片化情况，实现对单机GPU更为深入的分析。同时我们结合压缩感知算法以及Traincheck框架进行异常检测，提供了更为细粒度的监控能力。

[Neutrino](https://open-neutrino.github.io)是一款发表于 OSDI 25 的高效 GPU 性能分析与异常检测工具。通过CUDA汇编层级的信息采集实现了类似 eBPF 的编程接口，允许用户在 GPU Kernel 内部（如特定指令或调用处）插入 probe 获取运行时信息。系统核心包括一个 Hook Driver，用于运行时捕获 GPU 代码并分配 map 内存，以及一个 Probe Engine，负责根据定义在 GPU 代码中以汇编形式插入 Probe 和 Map。此外，Neutrino 拓展了经典的页面引用计数，引入 physical time 对齐不同线程的访存，并通过色深表达并行访存强度，提出了 Densified Memory Access Timeline (DMAT)，为开发者提供了更直观的 GPU Kernel 可视化分析能力。

我们发现，Neutrino 的 DMAT方案为 GPU 内核的内存访问可视化提供了一种新的方法。这种方法不仅能够对齐不同线程的访问时间，还能直观地表示并行访问的强度，有助于开发者更好地理解和优化 GPU 内核的性能。受到这个方案的启发，我们针对内存碎片化的动态演进提出了MDTP（Memory Distribution Timeline Plotter）方案。通过观察相邻时间帧之间内存布局的变化，开发者可以发现内存分配模式的规律性，比如是否存在周期性的分配释放行为，是否有特定算法阶段导致的内存碎片激增等。当内存空间中出现大量不连续的小色块时，说明该时间段内存碎片化严重；而当色块呈现较好的连续性和规整性时，则表明内存布局相对健康。


[Jumpstarter](https://www.usenix.org/conference/atc21/presentation/ma) 是一种基于压缩感知技术的多变量时间序列异常检测方法，发表于ATC 21，旨在解决现有学习方法初始化时间过长的问题。作者提出了 JumpStarter 方法。基于特定领域的洞察，论文作者为 JumpStarter 设计了一种基于形状的聚类算法以及一种抗异常值的采样算法。压缩感知基于如下思想，当原始时间序列不包含异常时，原始时间序列和重建的多变量时间序列（仅由低能量分量组成）之间的差异应该类似于白噪声。多变量时间序列中的异常，如抖动、突然下降，通常表现为包含高能分量的强信号，这与白噪声有很大不同。因此，我们可以通过检查滑动窗口中原始时间和重建的多元时间序列之间的差异是否与白噪声非常不同来判断时间序列是否包含异常。

我们发现，Jumpstarter 的压缩感知方法虽然能够快速初始化并检测异常，但其由于引入了凸优化求解器与Lesinn算法，速度较慢。我们在项目中借鉴了 Jumpstarter 的压缩感知思路，但通过自定义求解器提升凸优化求解效率，使用查找表优化了 lesinn 算法，平均加速比为 6.2倍。

[VersaGuardian](https://github.com/AIOps-Lab-NKU/VersaGuardian)是一种基于动态模态分解（Dynamic Mode Decomposition, DMD）技术的多变量时间序列异常检测工具，发表于IEEE Transactions on Networking 2025。VersaGuardian 能够在极短时间内完成系统初始化，无需大量训练数据即可快速部署。采用先进的 DMD 技术，大幅降低了计算复杂度。同时，VersaGuardian 对周期性的时间序列检测具有显著优势，能够有效识别和处理周期性模式中的异常。其核心思想是通过对多变量时间序列进行动态模态分解，提取出系统的动态特征，并基于这些特征进行异常检测。

我们发现，虽然 VersaGuardian 在周期性时间序列异常检测方面表现出色，但是对于非周期性时间序列或者是周期性不强的时间序列，异常检测能力较弱，而且方差波动较大。因此我们在异常检测方面采用了压缩感知算法与动态模态分解相结合的方式，通过周期特征判断选择那个方法，这能够快速适应多样负载，同时处理高维度数据，速度快，效率高。