Language model pretraining script from the official examples of the transformers library.
Trains GPT-2 on 

Modifications:
1. 10 steps per training/testing epoch.
2. stage annotations
3. skip instrumentation for the tokenization step