#!/usr/bin/env python3
"""
AIæ¨ç†æ—¥å¿—Bugåˆ†æå·¥å…·
è‡ªåŠ¨æ£€æµ‹æ¨ç†è¿‡ç¨‹ä¸­çš„é—®é¢˜å’Œbug
"""

import json
import re
from typing import Dict, List, Any
from src.reasoning_logger import ReasoningLogger


class ReasoningBugAnalyzer:
    """åˆ†ææ¨ç†æ—¥å¿—ä¸­çš„æ½œåœ¨é—®é¢˜å’Œbug"""

    def __init__(self, logger: ReasoningLogger):
        self.logger = logger

    def analyze_session_for_bugs(self, session_id: str) -> Dict[str, Any]:
        """
        åˆ†æä¼šè¯ä¸­çš„æ½œåœ¨bugå’Œé—®é¢˜

        Args:
            session_id: ä¼šè¯ID

        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        logs = self.logger.get_session_logs(session_id)
        analysis = self.logger.analyze_session(session_id)

        if not logs:
            return {"error": "No logs found"}

        issues = {
            "errors": [],
            "warnings": [],
            "performance_issues": [],
            "logical_inconsistencies": [],
            "incomplete_responses": [],
            "summary": {},
        }

        # æ£€æŸ¥é”™è¯¯
        issues["errors"] = self._detect_errors(logs)

        # æ£€æŸ¥è­¦å‘Š
        issues["warnings"] = self._detect_warnings(logs)

        # æ£€æŸ¥æ€§èƒ½é—®é¢˜
        issues["performance_issues"] = self._detect_performance_issues(logs, analysis)

        # æ£€æŸ¥é€»è¾‘ä¸ä¸€è‡´
        issues["logical_inconsistencies"] = self._detect_logical_issues(logs)

        # æ£€æŸ¥ä¸å®Œæ•´å“åº”
        issues["incomplete_responses"] = self._detect_incomplete_responses(logs)

        # ç”Ÿæˆæ‘˜è¦
        issues["summary"] = self._generate_summary(issues)

        return issues

    def _detect_errors(self, logs: List[Dict]) -> List[Dict]:
        """æ£€æµ‹æ˜ç¡®çš„é”™è¯¯"""
        errors = []

        for i, log in enumerate(logs):
            # æ£€æŸ¥é”™è¯¯step_type
            if log.get("step_type") == "error":
                errors.append(
                    {
                        "type": "explicit_error",
                        "step": i + 1,
                        "content": log.get("content", ""),
                        "severity": "high",
                    }
                )

            # æ£€æŸ¥å†…å®¹ä¸­çš„é”™è¯¯å…³é”®è¯
            content = log.get("content", "").lower()
            error_keywords = [
                "error",
                "failed",
                "exception",
                "traceback",
                "é”™è¯¯",
                "å¤±è´¥",
                "å¼‚å¸¸",
            ]

            for keyword in error_keywords:
                if keyword in content:
                    errors.append(
                        {
                            "type": "error_keyword",
                            "step": i + 1,
                            "keyword": keyword,
                            "content": log.get("content", "")[:200] + "...",
                            "severity": "medium",
                        }
                    )
                    break

        return errors

    def _detect_warnings(self, logs: List[Dict]) -> List[Dict]:
        """æ£€æµ‹è­¦å‘Š"""
        warnings = []

        for i, log in enumerate(logs):
            content = log.get("content", "").lower()

            # æ£€æŸ¥APIç›¸å…³é—®é¢˜
            if "api" in content and any(
                word in content for word in ["limit", "quota", "rate", "é™åˆ¶", "é…é¢"]
            ):
                warnings.append(
                    {
                        "type": "api_limit_warning",
                        "step": i + 1,
                        "content": log.get("content", "")[:200] + "...",
                        "severity": "medium",
                    }
                )

            # æ£€æŸ¥è¶…æ—¶é—®é¢˜
            if any(word in content for word in ["timeout", "è¶…æ—¶", "time out"]):
                warnings.append(
                    {
                        "type": "timeout_warning",
                        "step": i + 1,
                        "content": log.get("content", "")[:200] + "...",
                        "severity": "low",
                    }
                )

        return warnings

    def _detect_performance_issues(
        self, logs: List[Dict], analysis: Dict
    ) -> List[Dict]:
        """æ£€æµ‹æ€§èƒ½é—®é¢˜"""
        issues = []

        # æ£€æŸ¥å“åº”æ—¶é—´
        duration = analysis.get("duration", 0)
        if duration > 60:  # è¶…è¿‡60ç§’
            issues.append(
                {
                    "type": "slow_response",
                    "duration": duration,
                    "severity": "medium",
                    "description": f"å“åº”æ—¶é—´è¿‡é•¿: {duration:.2f}ç§’",
                }
            )

        # æ£€æŸ¥æ­¥éª¤æ•°é‡
        total_steps = analysis.get("total_steps", 0)
        if total_steps > 20:
            issues.append(
                {
                    "type": "too_many_steps",
                    "steps": total_steps,
                    "severity": "low",
                    "description": f"æ¨ç†æ­¥éª¤è¿‡å¤š: {total_steps}æ­¥",
                }
            )

        return issues

    def _detect_logical_issues(self, logs: List[Dict]) -> List[Dict]:
        """æ£€æµ‹é€»è¾‘ä¸ä¸€è‡´é—®é¢˜"""
        issues = []

        # æ£€æŸ¥æ˜¯å¦æœ‰å‰åçŸ›ç›¾çš„é™ˆè¿°
        contents = [
            log.get("content", "")
            for log in logs
            if log.get("step_type") == "response_complete"
        ]

        for i, content in enumerate(contents):
            # ç®€å•çš„çŸ›ç›¾æ£€æµ‹ï¼ˆå¯ä»¥æ‰©å±•ï¼‰
            if "ä¸æ˜¯" in content and "æ˜¯" in content:
                issues.append(
                    {
                        "type": "contradiction",
                        "step": i + 1,
                        "content": content[:200] + "...",
                        "severity": "medium",
                        "description": "å¯èƒ½å­˜åœ¨å‰åçŸ›ç›¾çš„é™ˆè¿°",
                    }
                )

        return issues

    def _detect_incomplete_responses(self, logs: List[Dict]) -> List[Dict]:
        """æ£€æµ‹ä¸å®Œæ•´çš„å“åº”"""
        issues = []

        # æ£€æŸ¥æ˜¯å¦æœ‰æœªå®Œæˆçš„streaming
        streaming_start_count = sum(
            1 for log in logs if log.get("step_type") == "streaming_start"
        )
        response_complete_count = sum(
            1 for log in logs if log.get("step_type") == "response_complete"
        )

        if streaming_start_count > response_complete_count:
            issues.append(
                {
                    "type": "incomplete_streaming",
                    "severity": "high",
                    "description": f"æœ‰{streaming_start_count - response_complete_count}ä¸ªæœªå®Œæˆçš„æµå¼å“åº”",
                }
            )

        # æ£€æŸ¥å“åº”æ˜¯å¦è¿‡çŸ­
        for i, log in enumerate(logs):
            if log.get("step_type") == "response_complete":
                content = log.get("content", "")
                if len(content.strip()) < 50:  # å“åº”å¤ªçŸ­
                    issues.append(
                        {
                            "type": "short_response",
                            "step": i + 1,
                            "length": len(content),
                            "severity": "low",
                            "description": f"å“åº”å†…å®¹è¿‡çŸ­: ä»…{len(content)}å­—ç¬¦",
                        }
                    )

        return issues

    def _generate_summary(self, issues: Dict) -> Dict:
        """ç”Ÿæˆé—®é¢˜æ‘˜è¦"""
        total_issues = (
            len(issues["errors"])
            + len(issues["warnings"])
            + len(issues["performance_issues"])
            + len(issues["logical_inconsistencies"])
            + len(issues["incomplete_responses"])
        )

        high_severity = sum(
            1
            for category in issues.values()
            if isinstance(category, list)
            for issue in category
            if isinstance(issue, dict) and issue.get("severity") == "high"
        )

        return {
            "total_issues": total_issues,
            "high_severity_count": high_severity,
            "errors_count": len(issues["errors"]),
            "warnings_count": len(issues["warnings"]),
            "performance_issues_count": len(issues["performance_issues"]),
            "recommendation": self._get_recommendation(issues),
        }

    def _get_recommendation(self, issues: Dict) -> str:
        """æ ¹æ®å‘ç°çš„é—®é¢˜æä¾›å»ºè®®"""
        total_issues = (
            len(issues["errors"])
            + len(issues["warnings"])
            + len(issues["performance_issues"])
            + len(issues["logical_inconsistencies"])
            + len(issues["incomplete_responses"])
        )

        high_severity = sum(
            1
            for category in issues.values()
            if isinstance(category, list)
            for issue in category
            if isinstance(issue, dict) and issue.get("severity") == "high"
        )

        if high_severity > 0:
            return "å‘ç°ä¸¥é‡é—®é¢˜ï¼Œéœ€è¦ç«‹å³å¤„ç†"
        elif total_issues > 5:
            return "å‘ç°å¤šä¸ªé—®é¢˜ï¼Œå»ºè®®ä¼˜åŒ–"
        elif total_issues > 0:
            return "å‘ç°å°‘é‡é—®é¢˜ï¼Œå¯ä»¥å¿½ç•¥æˆ–ç¨åå¤„ç†"
        else:
            return "æœªå‘ç°æ˜æ˜¾é—®é¢˜"


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨bugåˆ†æå™¨"""
    import argparse

    parser = argparse.ArgumentParser(description="åˆ†ææ¨ç†æ—¥å¿—ä¸­çš„bugå’Œé—®é¢˜")
    parser.add_argument("session_id", help="è¦åˆ†æçš„ä¼šè¯ID")
    parser.add_argument("--log-dir", help="æ—¥å¿—ç›®å½•")
    parser.add_argument("--export", help="å¯¼å‡ºåˆ†æç»“æœåˆ°æ–‡ä»¶")

    args = parser.parse_args()

    logger = ReasoningLogger(args.log_dir)
    analyzer = ReasoningBugAnalyzer(logger)

    print(f"ğŸ” åˆ†æä¼šè¯: {args.session_id}")
    print("=" * 50)

    # æ‰§è¡Œåˆ†æ
    results = analyzer.analyze_session_for_bugs(args.session_id)

    if "error" in results:
        print(f"âŒ é”™è¯¯: {results['error']}")
        return

    # æ˜¾ç¤ºç»“æœ
    summary = results["summary"]
    print(f"ğŸ“Š é—®é¢˜æ‘˜è¦:")
    print(f"  æ€»é—®é¢˜æ•°: {summary['total_issues']}")
    print(f"  ä¸¥é‡é—®é¢˜: {summary['high_severity_count']}")
    print(f"  é”™è¯¯: {summary['errors_count']}")
    print(f"  è­¦å‘Š: {summary['warnings_count']}")
    print(f"  æ€§èƒ½é—®é¢˜: {summary['performance_issues_count']}")
    print(f"  å»ºè®®: {summary['recommendation']}")
    print()

    # æ˜¾ç¤ºè¯¦ç»†é—®é¢˜
    for category, issues in results.items():
        if category == "summary" or not isinstance(issues, list) or not issues:
            continue

        print(f"ğŸ” {category.replace('_', ' ').title()}:")
        for issue in issues:
            severity_icon = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}.get(
                issue.get("severity", "low"), "âšª"
            )
            print(f"  {severity_icon} {issue.get('type', 'Unknown')}")
            if "description" in issue:
                print(f"     {issue['description']}")
            elif "content" in issue:
                print(f"     {issue['content'][:100]}...")
        print()

    # å¯¼å‡ºç»“æœ
    if args.export:
        with open(args.export, "w", encoding="utf-8") as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        print(f"ğŸ“ åˆ†æç»“æœå·²å¯¼å‡ºåˆ°: {args.export}")


if __name__ == "__main__":
    main()
