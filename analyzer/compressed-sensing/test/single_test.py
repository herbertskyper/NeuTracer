import os
import pandas as pd
import numpy as np
import time
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix
from detect import detect
import warnings
warnings.filterwarnings('ignore')

def calculate_evaluation_metrics(y_true, y_pred):
    """
    è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    """
    # åŸºæœ¬æŒ‡æ ‡
    precision = precision_score(y_true, y_pred, zero_division=0)
    recall = recall_score(y_true, y_pred, zero_division=0)
    f1 = f1_score(y_true, y_pred, zero_division=0)
    
    # æ··æ·†çŸ©é˜µ
    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
    
    # è®¡ç®—é¢å¤–æŒ‡æ ‡
    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
    accuracy = (tp + tn) / (tp + tn + fp + fn)
    
    metrics = {
        'precision': precision,
        'recall': recall,
        'f1_score': f1,
        'accuracy': accuracy,
        'specificity': specificity,
        'true_positives': int(tp),
        'false_positives': int(fp),
        'true_negatives': int(tn),
        'false_negatives': int(fn)
    }
    
    return metrics

def print_evaluation_results(metrics, title="è¯„ä¼°ç»“æœ"):
    """
    æ‰“å°æ ¼å¼åŒ–çš„è¯„ä¼°ç»“æœ
    """
    print(f"\n{'='*50}")
    print(f"{title}")
    print(f"{'='*50}")
    
    print(f"ç²¾ç¡®ç‡ (Precision):     {metrics['precision']:.4f}")
    print(f"å¬å›ç‡ (Recall):        {metrics['recall']:.4f}")
    print(f"F1åˆ†æ•° (F1-Score):      {metrics['f1_score']:.4f}")
    print(f"å‡†ç¡®ç‡ (Accuracy):      {metrics['accuracy']:.4f}")
    print(f"ç‰¹å¼‚æ€§ (Specificity):   {metrics['specificity']:.4f}")
    
    print(f"\næ··æ·†çŸ©é˜µ:")
    print(f"çœŸæ­£ä¾‹ (TP): {metrics['true_positives']:>6}")
    print(f"å‡æ­£ä¾‹ (FP): {metrics['false_positives']:>6}")
    print(f"çœŸè´Ÿä¾‹ (TN): {metrics['true_negatives']:>6}")
    print(f"å‡è´Ÿä¾‹ (FN): {metrics['false_negatives']:>6}")
    
    print(f"{'='*50}")

def test_single_service():
    """
    æµ‹è¯•å•ä¸ªæœåŠ¡æ–‡ä»¶
    """
    print("å¼€å§‹å•ä¸ªæ ·ä¾‹æµ‹è¯•...")
    
    # æ–‡ä»¶è·¯å¾„é…ç½®
    data_file = "./dataset/a.csv"
    label_file = "./dataset/b.csv"
    output_file = "./test_output/service0_result.csv"
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(data_file):
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
        return False
    
    if not os.path.exists(label_file):
        print(f"âŒ æ ‡ç­¾æ–‡ä»¶ä¸å­˜åœ¨: {label_file}")
        return False
    
    print(f"æ•°æ®æ–‡ä»¶: {data_file}")
    print(f"æ ‡ç­¾æ–‡ä»¶: {label_file}")
    print(f"è¾“å‡ºæ–‡ä»¶: {output_file}")
    
    try:
        # æ£€æŸ¥æ•°æ®æ–‡ä»¶å†…å®¹
        print("\n1. æ£€æŸ¥æ•°æ®æ–‡ä»¶...")
        data_df = pd.read_csv(data_file)
        print(f"   æ•°æ®å½¢çŠ¶: {data_df.shape}")
        print(f"   åˆ—åæ•°é‡: {len(data_df.columns)}")
        
        # æ£€æŸ¥æ ‡ç­¾æ–‡ä»¶å†…å®¹
        print("\n2. æ£€æŸ¥æ ‡ç­¾æ–‡ä»¶...")
        label_df = pd.read_csv(label_file, header=None)
        print(f"   æ ‡ç­¾å½¢çŠ¶: {label_df.shape}")
        print(f"   å¼‚å¸¸ç‚¹æ•°é‡: {label_df.iloc[:, 0].sum()} / {len(label_df)}")
        print(f"   å¼‚å¸¸ç‡: {label_df.iloc[:, 0].sum() / len(label_df) * 100:.2f}%")
        
        # è¿è¡Œå¼‚å¸¸æ£€æµ‹
        print("\n3. è¿è¡Œå¼‚å¸¸æ£€æµ‹...")
        start_time = time.time()
        
        detect(
            data_in=data_file,
            data_out=output_file,
            row_start=0,     
            col_start=0,     
            header=1        
        )
        
        processing_time = time.time() - start_time
        print(f"   å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’")
        
        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦ç”Ÿæˆ
        if not os.path.exists(output_file):
            print(f"âŒ è¾“å‡ºæ–‡ä»¶æœªç”Ÿæˆ: {output_file}")
            return False
        
        print("   âœ… å¼‚å¸¸æ£€æµ‹å®Œæˆ")
        
        # åŠ è½½é¢„æµ‹ç»“æœ
        print("\n4. åŠ è½½é¢„æµ‹ç»“æœ...")
        predictions = pd.read_csv(output_file, header=None).iloc[:, 0].values.astype(int)
        true_labels = label_df.iloc[:, 0].values.astype(int)
        
        print(f"   é¢„æµ‹ç»“æœå½¢çŠ¶: {predictions.shape}")
        print(f"   çœŸå®æ ‡ç­¾å½¢çŠ¶: {true_labels.shape}")
        
        # ç¡®ä¿é•¿åº¦åŒ¹é…
        min_length = min(len(predictions), len(true_labels))
        if len(predictions) != len(true_labels):
            print(f"   âš ï¸ é•¿åº¦ä¸åŒ¹é…ï¼Œæˆªå–è‡³ {min_length} ä¸ªæ•°æ®ç‚¹")
            predictions = predictions[:min_length]
            true_labels = true_labels[:min_length]
        
        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        print("\n5. è®¡ç®—è¯„ä¼°æŒ‡æ ‡...")
        metrics = calculate_evaluation_metrics(true_labels, predictions)
        
        # æ‰“å°è¯¦ç»†ç»“æœ
        print_evaluation_results(metrics, "service0 å¼‚å¸¸æ£€æµ‹è¯„ä¼°ç»“æœ")
        
        # æ‰“å°æ•°æ®ç»Ÿè®¡
        print(f"\næ•°æ®ç»Ÿè®¡:")
        print(f"æ€»æ•°æ®ç‚¹æ•°: {len(predictions)}")
        print(f"çœŸå®å¼‚å¸¸ç‚¹æ•°: {np.sum(true_labels)} ({np.sum(true_labels)/len(true_labels)*100:.2f}%)")
        print(f"é¢„æµ‹å¼‚å¸¸ç‚¹æ•°: {np.sum(predictions)} ({np.sum(predictions)/len(predictions)*100:.2f}%)")
        print(f"å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’")
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        result_summary = {
            'service_name': 'service0',
            'total_points': len(predictions),
            'true_anomalies': int(np.sum(true_labels)),
            'predicted_anomalies': int(np.sum(predictions)),
            'processing_time': processing_time,
            **metrics
        }
        
        summary_file = "./test_output/service0_detailed_result.csv"
        summary_df = pd.DataFrame([result_summary])
        summary_df.to_csv(summary_file, index=False)
        print(f"\nè¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {summary_file}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """
    ä¸»å‡½æ•°
    """
    print("=" * 60)
    print("å•ä¸ªæ ·ä¾‹æµ‹è¯•è„šæœ¬ - service0")
    print("=" * 60)
    
    success = test_single_service()
    
    if success:
        print(f"\nğŸ‰ å•ä¸ªæ ·ä¾‹æµ‹è¯•å®Œæˆ!")
        print(f"å¦‚æœç»“æœçœ‹èµ·æ¥åˆç†ï¼Œå¯ä»¥è¿è¡Œæ‰¹é‡æµ‹è¯•è„šæœ¬ã€‚")
    else:
        print(f"\nâŒ å•ä¸ªæ ·ä¾‹æµ‹è¯•å¤±è´¥!")
        print(f"è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶ä¿®å¤é—®é¢˜åå†è¿è¡Œæ‰¹é‡æµ‹è¯•ã€‚")

if __name__ == "__main__":
    main()